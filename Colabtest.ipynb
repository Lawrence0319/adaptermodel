{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0MadL3q2U0h",
        "outputId": "088f774d-a1d0-49eb-b519-35acb17215e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lr5QECibPZr",
        "outputId": "9986d6db-6ba4-4be1-9937-1b8149ae9b57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting adapter-transformers\n",
            "  Downloading adapter_transformers-3.2.1-py3-none-any.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from adapter-transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (4.66.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, adapter-transformers\n",
            "Successfully installed adapter-transformers-3.2.1 tokenizers-0.13.3\n"
          ]
        }
      ],
      "source": [
        "pip install adapter-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JuPeUJsXaTt",
        "outputId": "98f7e417-5801-4478-b40e-95e0511e214a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Lawrence0319/adapter-transformer-new.git\n",
            "  Cloning https://github.com/Lawrence0319/adapter-transformer-new.git to /tmp/pip-req-build-mtzpx9xw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Lawrence0319/adapter-transformer-new.git /tmp/pip-req-build-mtzpx9xw\n",
            "  Resolved https://github.com/Lawrence0319/adapter-transformer-new.git to commit 0e9b86a5006b4b64b22c76009b27ffeb2d0a21c2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from adapter-transformers==3.2.1)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from adapter-transformers==3.2.1)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.2.1) (4.66.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers==3.2.1) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers==3.2.1) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers==3.2.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers==3.2.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers==3.2.1) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers==3.2.1) (2023.7.22)\n",
            "Building wheels for collected packages: adapter-transformers\n",
            "  Building wheel for adapter-transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adapter-transformers: filename=adapter_transformers-3.2.1-py3-none-any.whl size=6427020 sha256=c3b96dc135df77d1d747cbecedd443d7d7377167bef4454ff90cc8aabe9b1739\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u74bu_fw/wheels/bb/9b/16/28eb9d4b00fe36462b938537f7b2c6e6ba52ae2c92d41d25d5\n",
            "Successfully built adapter-transformers\n",
            "Installing collected packages: tokenizers, huggingface-hub, adapter-transformers\n",
            "Successfully installed adapter-transformers-3.2.1 huggingface-hub-0.16.4 tokenizers-0.13.3\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/Lawrence0319/adapter-transformer-new.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJlDySGVafbI",
        "outputId": "429bc25f-ffe4-4a25-a101-ba9a509aa5ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, responses, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.14.4 dill-0.3.7 evaluate-0.4.0 multiprocess-0.70.15 responses-0.18.0 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "pip install datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGYqDLEFahxP",
        "outputId": "5e87c63a-9a99-401f-8ead-1dcd9e7f9a96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: tensorflow 2.12.0\n",
            "Uninstalling tensorflow-2.12.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.12.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled tensorflow-2.12.0\n"
          ]
        }
      ],
      "source": [
        "pip uninstall tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFTtt-aWXHF9",
        "outputId": "852663fe-eff2-46c4-ff17-77f7f8ba80e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "08/14/2023 14:07:49 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "08/14/2023 14:07:49 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=passive,\n",
            "log_on_each_node=True,\n",
            "logging_dir=drive/MyDrive/adapter_news_s1csqa_nl/runs/Aug14_14-07-49_fe7e1f8a2b68,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=drive/MyDrive/adapter_news_s1csqa_nl,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=drive/MyDrive/adapter_news_s1csqa_nl,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=None' instead.\n",
            "  warnings.warn(\n",
            "Using custom data configuration default-7f2590a624265c1e\n",
            "08/14/2023 14:07:50 - INFO - datasets.builder - Using custom data configuration default-7f2590a624265c1e\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "08/14/2023 14:07:50 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "Generating dataset json (/root/.cache/huggingface/datasets/json/default-7f2590a624265c1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
            "08/14/2023 14:07:50 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-7f2590a624265c1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-7f2590a624265c1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n",
            "08/14/2023 14:07:50 - INFO - datasets.builder - Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-7f2590a624265c1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n",
            "Downloading data files: 100% 2/2 [00:00<00:00, 5687.19it/s]\n",
            "Downloading took 0.0 min\n",
            "08/14/2023 14:07:50 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
            "Checksum Computation took 0.0 min\n",
            "08/14/2023 14:07:50 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
            "Extracting data files: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "Generating train split\n",
            "08/14/2023 14:07:51 - INFO - datasets.builder - Generating train split\n",
            "Generating train split: 8000 examples [00:00, 11608.47 examples/s]\n",
            "Generating test split\n",
            "08/14/2023 14:07:52 - INFO - datasets.builder - Generating test split\n",
            "Generating test split: 1500 examples [00:00, 5692.69 examples/s]\n",
            "Unable to verify splits sizes.\n",
            "08/14/2023 14:07:52 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-7f2590a624265c1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n",
            "08/14/2023 14:07:52 - INFO - datasets.builder - Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-7f2590a624265c1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n",
            "Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 3.50MB/s]\n",
            "[INFO|configuration_utils.py:666] 2023-08-14 14:07:52,661 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/config.json\n",
            "[INFO|configuration_utils.py:718] 2023-08-14 14:07:52,664 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 206kB/s]\n",
            "[INFO|configuration_utils.py:666] 2023-08-14 14:07:52,774 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/config.json\n",
            "[INFO|configuration_utils.py:718] 2023-08-14 14:07:52,775 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 3.74MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 466k/466k [00:00<00:00, 17.8MB/s]\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-08-14 14:07:53,230 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-08-14 14:07:53,230 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-08-14 14:07:53,230 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-08-14 14:07:53,230 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-08-14 14:07:53,230 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/tokenizer_config.json\n",
            "[INFO|configuration_utils.py:666] 2023-08-14 14:07:53,231 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/config.json\n",
            "[INFO|configuration_utils.py:718] 2023-08-14 14:07:53,231 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Downloading pytorch_model.bin: 100% 440M/440M [00:10<00:00, 41.4MB/s]\n",
            "[INFO|modeling_utils.py:2275] 2023-08-14 14:08:04,115 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/pytorch_model.bin\n",
            "[WARNING|modeling_utils.py:2850] 2023-08-14 14:08:05,550 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2862] 2023-08-14 14:08:05,550 >> Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fetching 6 files:   0% 0/6 [00:00<?, ?it/s]\n",
            "Downloading (…)4ff9f/.gitattributes: 100% 1.18k/1.18k [00:00<00:00, 5.30MB/s]\n",
            "Fetching 6 files:  17% 1/6 [00:00<00:03,  1.66it/s]\n",
            "Downloading (…)f9f/head_config.json: 100% 338/338 [00:00<00:00, 1.96MB/s]\n",
            "\n",
            "Downloading (…)a99d54ff9f/README.md: 100% 2.24k/2.24k [00:00<00:00, 12.7MB/s]\n",
            "\n",
            "Downloading (…)/adapter_config.json: 100% 571/571 [00:00<00:00, 2.48MB/s]\n",
            "Fetching 6 files:  50% 3/6 [00:00<00:00,  5.10it/s]\n",
            "Downloading pytorch_adapter.bin:   0% 0.00/3.59M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model_head.bin: 100% 7.22k/7.22k [00:00<00:00, 32.1MB/s]\n",
            "Downloading pytorch_adapter.bin: 100% 3.59M/3.59M [00:00<00:00, 43.1MB/s]\n",
            "Fetching 6 files: 100% 6/6 [00:00<00:00,  6.93it/s]\n",
            "[INFO|loading.py:77] 2023-08-14 14:08:06,488 >> Loading module configuration from /root/.cache/huggingface/hub/models--AdapterHub--bert-base-uncased-pf-newsqa/snapshots/1d25a40c0cef2e4a090fd691da91bfa99d54ff9f/adapter_config.json\n",
            "[INFO|configuration.py:734] 2023-08-14 14:08:06,489 >> Adding adapter 'news_qa'.\n",
            "[INFO|loading.py:146] 2023-08-14 14:08:06,513 >> Loading module weights from /root/.cache/huggingface/hub/models--AdapterHub--bert-base-uncased-pf-newsqa/snapshots/1d25a40c0cef2e4a090fd691da91bfa99d54ff9f/pytorch_adapter.bin\n",
            "[INFO|loading.py:77] 2023-08-14 14:08:06,518 >> Loading module configuration from /root/.cache/huggingface/hub/models--AdapterHub--bert-base-uncased-pf-newsqa/snapshots/1d25a40c0cef2e4a090fd691da91bfa99d54ff9f/head_config.json\n",
            "[WARNING|loading.py:698] 2023-08-14 14:08:06,519 >> Model class 'BertModelWithHeads' of found prediction head does not match current model class.\n",
            "[INFO|utils.py:640] 2023-08-14 14:08:06,728 >> Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/squad1/bert-base-uncased/pfeiffer/bert-base-uncased_qa_squad1_pfeiffer.zip.\n",
            "[INFO|utils.py:313] 2023-08-14 14:08:07,459 >> https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/squad1/bert-base-uncased/pfeiffer/bert-base-uncased_qa_squad1_pfeiffer.zip not found in cache or force_download set to True, downloading to /content/~/.cache/torch/adapters/tmp4gfhq7i2\n",
            "Downloading (…)_squad1_pfeiffer.zip: 100% 3.60M/3.60M [00:00<00:00, 5.64MB/s]\n",
            "[INFO|utils.py:323] 2023-08-14 14:08:08,616 >> storing https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/squad1/bert-base-uncased/pfeiffer/bert-base-uncased_qa_squad1_pfeiffer.zip in cache at ~/.cache/torch/adapters/fa86eae6a17e8805b55d32ed6e3d696deb2f3c17799b257d0cf4e435d5504601.3e6e6394591ca4a75ce6094a0cb80b575a38487287012167d48bd84ace1e83eb\n",
            "[INFO|utils.py:331] 2023-08-14 14:08:08,616 >> creating metadata file for ~/.cache/torch/adapters/fa86eae6a17e8805b55d32ed6e3d696deb2f3c17799b257d0cf4e435d5504601.3e6e6394591ca4a75ce6094a0cb80b575a38487287012167d48bd84ace1e83eb\n",
            "[INFO|loading.py:77] 2023-08-14 14:08:08,629 >> Loading module configuration from ~/.cache/torch/adapters/fa86eae6a17e8805b55d32ed6e3d696deb2f3c17799b257d0cf4e435d5504601-3e6e6394591ca4a75ce6094a0cb80b575a38487287012167d48bd84ace1e83eb-extracted/adapter_config.json\n",
            "[INFO|configuration.py:734] 2023-08-14 14:08:08,630 >> Adding adapter 'squad1'.\n",
            "[INFO|loading.py:146] 2023-08-14 14:08:08,657 >> Loading module weights from ~/.cache/torch/adapters/fa86eae6a17e8805b55d32ed6e3d696deb2f3c17799b257d0cf4e435d5504601-3e6e6394591ca4a75ce6094a0cb80b575a38487287012167d48bd84ace1e83eb-extracted/pytorch_adapter.bin\n",
            "[INFO|loading.py:164] 2023-08-14 14:08:08,663 >> Some module weights could not be found in loaded weights file: bert.invertible_adapters.squad1.F.0.weight, bert.invertible_adapters.squad1.F.0.bias, bert.invertible_adapters.squad1.F.2.weight, bert.invertible_adapters.squad1.F.2.bias, bert.invertible_adapters.squad1.G.0.weight, bert.invertible_adapters.squad1.G.0.bias, bert.invertible_adapters.squad1.G.2.weight, bert.invertible_adapters.squad1.G.2.bias\n",
            "[INFO|loading.py:77] 2023-08-14 14:08:08,663 >> Loading module configuration from ~/.cache/torch/adapters/fa86eae6a17e8805b55d32ed6e3d696deb2f3c17799b257d0cf4e435d5504601-3e6e6394591ca4a75ce6094a0cb80b575a38487287012167d48bd84ace1e83eb-extracted/head_config.json\n",
            "[WARNING|loading.py:698] 2023-08-14 14:08:08,664 >> Model class 'BertModelWithHeads' of found prediction head does not match current model class.\n",
            "[INFO|utils.py:715] 2023-08-14 14:08:08,664 >> Attempting to load adapter from source 'ah'...\n",
            "[INFO|utils.py:313] 2023-08-14 14:08:09,072 >> https://raw.githubusercontent.com/Adapter-Hub/Hub/master/dist/v2/index/bert-base-uncased.json not found in cache or force_download set to True, downloading to /content/~/.cache/torch/adapters/tmpoi4dmzz5\n",
            "Downloading (…)rt-base-uncased.json: 9.31kB [00:00, 30.7MB/s]     \n",
            "[INFO|utils.py:323] 2023-08-14 14:08:09,182 >> storing https://raw.githubusercontent.com/Adapter-Hub/Hub/master/dist/v2/index/bert-base-uncased.json in cache at ~/.cache/torch/adapters/22e416a3791c0b8e1aafcfac89db490ae05250204ed58e5d81a8645b0726dda0.b141886e1b58ad87e04b024247bf438580086cd7bd78529838848a12d9323e20\n",
            "[INFO|utils.py:331] 2023-08-14 14:08:09,182 >> creating metadata file for ~/.cache/torch/adapters/22e416a3791c0b8e1aafcfac89db490ae05250204ed58e5d81a8645b0726dda0.b141886e1b58ad87e04b024247bf438580086cd7bd78529838848a12d9323e20\n",
            "[INFO|utils.py:720] 2023-08-14 14:08:09,185 >> No adapter with name 'AdapterHub/bert-base-uncased-pf-commonsense_qa' was found in the adapter index.\n",
            "[INFO|utils.py:721] 2023-08-14 14:08:09,185 >> Attempting to load adapter from source 'hf'...\n",
            "Fetching 6 files:   0% 0/6 [00:00<?, ?it/s]\n",
            "Downloading (…)c65/head_config.json: 100% 412/412 [00:00<00:00, 1.36MB/s]\n",
            "\n",
            "Downloading (…)0a28b91c65/README.md: 100% 2.22k/2.22k [00:00<00:00, 9.96MB/s]\n",
            "\n",
            "Downloading (…)/adapter_config.json: 100% 579/579 [00:00<00:00, 3.89MB/s]\n",
            "\n",
            "Downloading (…)91c65/.gitattributes: 100% 1.18k/1.18k [00:00<00:00, 7.72MB/s]\n",
            "Fetching 6 files:  17% 1/6 [00:00<00:00,  6.99it/s]\n",
            "Downloading pytorch_model_head.bin:   0% 0.00/2.37M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model_head.bin: 100% 2.37M/2.37M [00:00<00:00, 34.3MB/s]\n",
            "Downloading pytorch_adapter.bin: 100% 3.60M/3.60M [00:00<00:00, 45.9MB/s]\n",
            "Fetching 6 files: 100% 6/6 [00:00<00:00, 16.37it/s]\n",
            "[INFO|loading.py:77] 2023-08-14 14:08:09,635 >> Loading module configuration from /root/.cache/huggingface/hub/models--AdapterHub--bert-base-uncased-pf-commonsense_qa/snapshots/db0cd07e2eea84080444ae8608bcac0a28b91c65/adapter_config.json\n",
            "[INFO|configuration.py:734] 2023-08-14 14:08:09,635 >> Adding adapter 'csqa'.\n",
            "[INFO|loading.py:146] 2023-08-14 14:08:09,658 >> Loading module weights from /root/.cache/huggingface/hub/models--AdapterHub--bert-base-uncased-pf-commonsense_qa/snapshots/db0cd07e2eea84080444ae8608bcac0a28b91c65/pytorch_adapter.bin\n",
            "[INFO|loading.py:77] 2023-08-14 14:08:09,666 >> Loading module configuration from /root/.cache/huggingface/hub/models--AdapterHub--bert-base-uncased-pf-commonsense_qa/snapshots/db0cd07e2eea84080444ae8608bcac0a28b91c65/head_config.json\n",
            "[WARNING|loading.py:698] 2023-08-14 14:08:09,666 >> Model class 'BertModelWithHeads' of found prediction head does not match current model class.\n",
            "[INFO|configuration.py:783] 2023-08-14 14:08:09,666 >> Adding AdapterFusion 'news_qa,squad1,csqa'.\n",
            "query!\n",
            "key!\n",
            "value!\n",
            "query!\n",
            "key!\n",
            "value!\n",
            "query!\n",
            "key!\n",
            "value!\n",
            "query!\n",
            "key!\n",
            "value!\n",
            "query!\n",
            "key!\n",
            "value!\n",
            "query!\n",
            "key!\n",
            "value!\n",
            "query!\n",
            "key!\n",
            "value!\n",
            "query!\n",
            "key!\n",
            "value!\n",
            "query!\n",
            "key!\n",
            "value!\n",
            "query!\n",
            "key!\n",
            "value!\n",
            "query!\n",
            "key!\n",
            "value!\n",
            "query!\n",
            "key!\n",
            "value!\n",
            "Running tokenizer on train dataset:   0% 0/8000 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7f2590a624265c1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3e773b15931b9d09.arrow\n",
            "08/14/2023 14:08:14 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7f2590a624265c1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3e773b15931b9d09.arrow\n",
            "Running tokenizer on train dataset: 100% 8000/8000 [00:28<00:00, 281.15 examples/s]\n",
            "Running tokenizer on prediction dataset:   0% 0/1500 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7f2590a624265c1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ca7f0d0faba77305.arrow\n",
            "08/14/2023 14:08:40 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7f2590a624265c1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ca7f0d0faba77305.arrow\n",
            "Running tokenizer on prediction dataset: 100% 1500/1500 [00:06<00:00, 214.97 examples/s]\n",
            "Downloading builder script: 100% 4.53k/4.53k [00:00<00:00, 12.6MB/s]\n",
            "Downloading extra modules: 100% 3.32k/3.32k [00:00<00:00, 10.4MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1650] 2023-08-14 14:08:52,024 >> ***** Running training *****\n",
            "[INFO|trainer.py:1651] 2023-08-14 14:08:52,024 >>   Num examples = 25366\n",
            "[INFO|trainer.py:1652] 2023-08-14 14:08:52,024 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1653] 2023-08-14 14:08:52,024 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:1654] 2023-08-14 14:08:52,024 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer.py:1655] 2023-08-14 14:08:52,024 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1656] 2023-08-14 14:08:52,024 >>   Total optimization steps = 9513\n",
            "[INFO|trainer.py:1657] 2023-08-14 14:08:52,026 >>   Number of trainable parameters = 21253634\n",
            "{'loss': 1.6564, 'learning_rate': 4.737201723956691e-05, 'epoch': 0.16}\n",
            "  5% 500/9513 [06:30<2:01:08,  1.24it/s][INFO|trainer.py:141] 2023-08-14 14:15:22,889 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500\n",
            "[INFO|loading.py:60] 2023-08-14 14:15:22,909 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:15:22,938 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:15:22,941 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:15:22,951 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:15:22,956 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:15:22,983 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:15:22,987 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:15:22,998 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:15:23,003 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:15:23,032 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:15:23,035 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:15:23,044 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:15:23,050 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:15:23,275 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 14:15:23,288 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 14:15:23,294 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 1.2062, 'learning_rate': 4.474403447913382e-05, 'epoch': 0.32}\n",
            " 11% 1000/9513 [13:14<1:54:55,  1.23it/s][INFO|trainer.py:141] 2023-08-14 14:22:06,519 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000\n",
            "[INFO|loading.py:60] 2023-08-14 14:22:06,525 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:22:06,556 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:22:06,560 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:22:06,570 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:22:06,576 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:22:06,605 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:22:06,610 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:22:06,621 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:22:06,627 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:22:06,655 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:22:06,681 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:22:06,691 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:22:06,697 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:22:06,911 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 14:22:06,916 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 14:22:06,920 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000/special_tokens_map.json\n",
            "{'loss': 1.1337, 'learning_rate': 4.211605171870073e-05, 'epoch': 0.47}\n",
            " 16% 1500/9513 [19:57<1:46:26,  1.25it/s][INFO|trainer.py:141] 2023-08-14 14:28:49,716 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500\n",
            "[INFO|loading.py:60] 2023-08-14 14:28:49,722 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:28:49,755 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:28:49,759 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:28:49,770 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:28:49,776 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:28:49,819 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:28:49,824 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:28:49,836 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:28:49,842 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:28:49,877 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:28:49,882 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:28:49,895 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:28:49,901 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:28:50,149 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 14:28:50,154 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 14:28:50,159 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 14:28:51,184 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-500] due to args.save_total_limit\n",
            "{'loss': 1.0878, 'learning_rate': 3.9488068958267636e-05, 'epoch': 0.63}\n",
            " 21% 2000/9513 [26:40<1:39:31,  1.26it/s][INFO|trainer.py:141] 2023-08-14 14:35:32,963 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000\n",
            "[INFO|loading.py:60] 2023-08-14 14:35:32,973 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:35:33,009 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:35:33,013 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:35:33,023 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:35:33,028 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:35:33,057 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:35:33,061 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:35:33,069 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:35:33,075 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:35:33,101 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:35:33,105 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:35:33,113 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:35:33,119 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:35:33,332 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 14:35:33,337 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 14:35:33,341 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 14:35:34,552 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1000] due to args.save_total_limit\n",
            "{'loss': 0.9853, 'learning_rate': 3.6860086197834545e-05, 'epoch': 0.79}\n",
            " 26% 2500/9513 [33:24<1:33:24,  1.25it/s][INFO|trainer.py:141] 2023-08-14 14:42:16,439 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500\n",
            "[INFO|loading.py:60] 2023-08-14 14:42:16,449 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:42:16,482 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:42:16,487 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:42:16,498 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:42:16,504 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:42:16,538 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:42:16,542 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:42:16,552 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:42:16,557 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:42:16,591 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:42:16,596 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:42:16,607 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:42:16,613 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:42:16,848 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 14:42:16,853 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 14:42:16,857 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 14:42:18,149 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-1500] due to args.save_total_limit\n",
            "{'loss': 0.9407, 'learning_rate': 3.423210343740145e-05, 'epoch': 0.95}\n",
            " 32% 3000/9513 [40:08<1:28:05,  1.23it/s][INFO|trainer.py:141] 2023-08-14 14:49:00,789 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000\n",
            "[INFO|loading.py:60] 2023-08-14 14:49:00,795 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:49:00,828 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:49:00,832 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:49:00,843 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:49:00,849 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:49:00,877 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:49:00,881 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:49:00,891 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:49:00,897 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:49:00,927 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:49:00,931 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:49:00,941 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:49:00,946 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:49:01,204 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 14:49:01,211 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 14:49:01,216 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 14:49:01,925 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2000] due to args.save_total_limit\n",
            "{'loss': 0.9671, 'learning_rate': 3.160412067696836e-05, 'epoch': 1.1}\n",
            " 37% 3500/9513 [46:49<1:19:53,  1.25it/s][INFO|trainer.py:141] 2023-08-14 14:55:41,674 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500\n",
            "[INFO|loading.py:60] 2023-08-14 14:55:41,680 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:55:41,708 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:55:41,712 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:55:41,720 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:55:41,726 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:55:41,753 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:55:41,757 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:55:41,765 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:55:41,770 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:55:41,797 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:55:41,801 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:55:41,810 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 14:55:41,816 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 14:55:42,023 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 14:55:42,029 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 14:55:42,033 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 14:55:42,647 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-2500] due to args.save_total_limit\n",
            "{'loss': 0.87, 'learning_rate': 2.8976137916535267e-05, 'epoch': 1.26}\n",
            " 42% 4000/9513 [53:31<1:14:00,  1.24it/s][INFO|trainer.py:141] 2023-08-14 15:02:23,503 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000\n",
            "[INFO|loading.py:60] 2023-08-14 15:02:23,508 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:02:23,535 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:02:23,539 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:02:23,552 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:02:23,558 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:02:23,583 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:02:23,587 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:02:23,595 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:02:23,601 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:02:23,628 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:02:23,632 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:02:23,643 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:02:23,649 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:02:23,852 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 15:02:23,865 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 15:02:23,871 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 15:02:24,607 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3000] due to args.save_total_limit\n",
            "{'loss': 0.9589, 'learning_rate': 2.634815515610218e-05, 'epoch': 1.42}\n",
            " 47% 4500/9513 [1:00:13<1:06:37,  1.25it/s][INFO|trainer.py:141] 2023-08-14 15:09:05,397 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500\n",
            "[INFO|loading.py:60] 2023-08-14 15:09:05,402 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:09:05,433 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:09:05,437 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:09:05,445 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:09:05,451 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:09:05,478 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:09:05,482 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:09:05,490 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:09:05,496 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:09:05,522 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:09:05,526 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:09:05,535 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:09:05,542 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:09:05,746 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 15:09:05,761 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 15:09:05,846 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 15:09:06,469 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-3500] due to args.save_total_limit\n",
            "{'loss': 0.9324, 'learning_rate': 2.3720172395669087e-05, 'epoch': 1.58}\n",
            " 53% 5000/9513 [1:06:54<1:00:46,  1.24it/s][INFO|trainer.py:141] 2023-08-14 15:15:47,028 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000\n",
            "[INFO|loading.py:60] 2023-08-14 15:15:47,034 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:15:47,066 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:15:47,071 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:15:47,081 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:15:47,087 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:15:47,120 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:15:47,124 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:15:47,134 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:15:47,139 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:15:47,170 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:15:47,174 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:15:47,203 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:15:47,209 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:15:47,434 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 15:15:47,439 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 15:15:47,450 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 15:15:48,065 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4000] due to args.save_total_limit\n",
            "{'loss': 0.915, 'learning_rate': 2.1092189635235992e-05, 'epoch': 1.73}\n",
            " 58% 5500/9513 [1:13:36<53:32,  1.25it/s][INFO|trainer.py:141] 2023-08-14 15:22:29,048 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500\n",
            "[INFO|loading.py:60] 2023-08-14 15:22:29,054 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:22:29,082 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:22:29,085 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:22:29,094 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:22:29,100 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:22:29,125 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:22:29,129 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:22:29,139 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:22:29,145 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:22:29,171 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:22:29,192 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:22:29,201 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:22:29,206 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:22:29,404 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 15:22:29,409 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 15:22:29,421 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 15:22:30,012 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-4500] due to args.save_total_limit\n",
            "{'loss': 0.8847, 'learning_rate': 1.8464206874802904e-05, 'epoch': 1.89}\n",
            " 63% 6000/9513 [1:20:19<46:58,  1.25it/s][INFO|trainer.py:141] 2023-08-14 15:29:11,871 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000\n",
            "[INFO|loading.py:60] 2023-08-14 15:29:11,876 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:29:11,903 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:29:11,907 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:29:11,915 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:29:11,921 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:29:11,949 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:29:11,953 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:29:11,960 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:29:11,982 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:29:12,010 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:29:12,014 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:29:12,022 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:29:12,029 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:29:12,232 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 15:29:12,237 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 15:29:12,241 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 15:29:12,855 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5000] due to args.save_total_limit\n",
            "{'loss': 0.868, 'learning_rate': 1.583622411436981e-05, 'epoch': 2.05}\n",
            " 68% 6500/9513 [1:27:01<39:50,  1.26it/s][INFO|trainer.py:141] 2023-08-14 15:35:54,029 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500\n",
            "[INFO|loading.py:60] 2023-08-14 15:35:54,034 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:35:54,061 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:35:54,065 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:35:54,075 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:35:54,082 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:35:54,111 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:35:54,114 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:35:54,125 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:35:54,148 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:35:54,173 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:35:54,177 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:35:54,185 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:35:54,191 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:35:54,430 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 15:35:54,446 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 15:35:54,458 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 15:35:55,223 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-5500] due to args.save_total_limit\n",
            "{'loss': 0.8404, 'learning_rate': 1.3208241353936717e-05, 'epoch': 2.21}\n",
            " 74% 7000/9513 [1:33:44<33:41,  1.24it/s][INFO|trainer.py:141] 2023-08-14 15:42:36,636 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000\n",
            "[INFO|loading.py:60] 2023-08-14 15:42:36,641 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:42:36,667 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:42:36,672 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:42:36,681 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:42:36,702 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:42:36,728 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:42:36,732 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:42:36,740 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:42:36,746 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:42:36,771 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:42:36,775 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:42:36,783 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:42:36,790 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:42:36,993 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 15:42:36,998 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 15:42:37,003 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 15:42:37,563 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6000] due to args.save_total_limit\n",
            "{'loss': 0.8678, 'learning_rate': 1.0580258593503627e-05, 'epoch': 2.37}\n",
            " 79% 7500/9513 [1:40:27<26:44,  1.25it/s][INFO|trainer.py:141] 2023-08-14 15:49:19,099 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500\n",
            "[INFO|loading.py:60] 2023-08-14 15:49:19,105 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:49:19,133 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:49:19,137 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:49:19,146 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:49:19,151 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:49:19,177 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:49:19,181 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:49:19,190 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:49:19,197 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:49:19,223 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:49:19,226 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:49:19,234 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:49:19,240 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:49:19,445 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 15:49:19,450 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 15:49:19,492 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 15:49:20,074 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-6500] due to args.save_total_limit\n",
            "{'loss': 0.8014, 'learning_rate': 7.952275833070536e-06, 'epoch': 2.52}\n",
            " 84% 8000/9513 [1:47:08<20:17,  1.24it/s][INFO|trainer.py:141] 2023-08-14 15:56:00,862 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000\n",
            "[INFO|loading.py:60] 2023-08-14 15:56:00,868 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:56:00,898 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:56:00,901 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:56:00,911 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:56:00,916 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:56:00,942 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:56:00,946 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:56:00,956 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:56:00,961 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:56:00,987 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:56:00,993 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:56:01,003 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 15:56:01,009 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 15:56:01,216 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 15:56:01,287 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 15:56:01,293 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 15:56:01,901 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7000] due to args.save_total_limit\n",
            "{'loss': 0.8252, 'learning_rate': 5.324293072637443e-06, 'epoch': 2.68}\n",
            " 89% 8500/9513 [1:53:50<13:26,  1.26it/s][INFO|trainer.py:141] 2023-08-14 16:02:42,886 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500\n",
            "[INFO|loading.py:60] 2023-08-14 16:02:42,891 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:02:42,921 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:02:42,924 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:02:42,933 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:02:42,938 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:02:42,963 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:02:42,967 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:02:42,980 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:02:42,986 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:02:43,015 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:02:43,018 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:02:43,026 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:02:43,046 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:02:43,245 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 16:02:43,249 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 16:02:43,253 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 16:02:43,992 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-7500] due to args.save_total_limit\n",
            "{'loss': 0.8334, 'learning_rate': 2.6963103122043523e-06, 'epoch': 2.84}\n",
            " 95% 9000/9513 [2:00:33<06:52,  1.24it/s][INFO|trainer.py:141] 2023-08-14 16:09:25,244 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000\n",
            "[INFO|loading.py:60] 2023-08-14 16:09:25,249 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:09:25,278 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:09:25,282 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:09:25,292 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:09:25,297 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:09:25,324 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:09:25,328 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:09:25,335 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:09:25,356 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:09:25,392 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:09:25,396 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:09:25,404 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:09:25,410 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:09:25,608 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 16:09:25,619 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 16:09:25,632 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 16:09:26,267 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8000] due to args.save_total_limit\n",
            "{'loss': 0.8476, 'learning_rate': 6.832755177126038e-08, 'epoch': 3.0}\n",
            "100% 9500/9513 [2:07:15<00:10,  1.25it/s][INFO|trainer.py:141] 2023-08-14 16:16:08,063 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:08,070 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:08,107 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:08,111 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:08,121 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:08,126 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:08,154 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:08,158 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:08,182 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:08,188 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:08,216 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:08,220 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:08,230 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:08,236 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:08,454 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 16:16:08,459 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 16:16:08,462 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-9500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-14 16:16:09,055 >> Deleting older checkpoint [drive/MyDrive/adapter_news_s1csqa_nl/checkpoint-8500] due to args.save_total_limit\n",
            "100% 9513/9513 [2:07:27<00:00,  1.33it/s][INFO|trainer.py:1901] 2023-08-14 16:16:19,995 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 7647.9692, 'train_samples_per_second': 9.95, 'train_steps_per_second': 1.244, 'train_loss': 0.9693170803322296, 'epoch': 3.0}\n",
            "100% 9513/9513 [2:07:27<00:00,  1.24it/s]\n",
            "[INFO|trainer.py:141] 2023-08-14 16:16:20,018 >> Saving model checkpoint to drive/MyDrive/adapter_news_s1csqa_nl\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:20,023 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:20,055 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:20,060 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:20,070 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:20,075 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:20,104 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:20,108 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:20,135 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:20,142 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:20,171 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:20,174 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:20,184 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/csqa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:20,190 >> Configuration saved in drive/MyDrive/adapter_news_s1csqa_nl/news_qa,squad1,csqa/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:20,423 >> Module weights saved in drive/MyDrive/adapter_news_s1csqa_nl/news_qa,squad1,csqa/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-14 16:16:20,441 >> tokenizer config file saved in drive/MyDrive/adapter_news_s1csqa_nl/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-14 16:16:20,452 >> Special tokens file saved in drive/MyDrive/adapter_news_s1csqa_nl/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =     0.9693\n",
            "  train_runtime            = 2:07:27.96\n",
            "  train_samples            =      25366\n",
            "  train_samples_per_second =       9.95\n",
            "  train_steps_per_second   =      1.244\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:20,521 >> Configuration saved in drive/MyDrive/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:20,798 >> Module weights saved in drive/MyDrive/pytorch_model_adapter_fusion.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:20,804 >> Configuration saved in drive/MyDrive/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:20,842 >> Module weights saved in drive/MyDrive/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:21,352 >> Configuration saved in drive/MyDrive/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:21,362 >> Module weights saved in drive/MyDrive/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:21,368 >> Configuration saved in drive/MyDrive/squad1/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:21,395 >> Module weights saved in drive/MyDrive/squad1/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:21,399 >> Configuration saved in drive/MyDrive/squad1/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:21,407 >> Module weights saved in drive/MyDrive/squad1/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:21,413 >> Configuration saved in drive/MyDrive/csqa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:21,441 >> Module weights saved in drive/MyDrive/csqa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-14 16:16:21,445 >> Configuration saved in drive/MyDrive/csqa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-14 16:16:21,454 >> Module weights saved in drive/MyDrive/csqa/pytorch_model_head.bin\n",
            "08/14/2023 16:16:21 - INFO - __main__ - *** Predict ***\n",
            "[INFO|trainer.py:710] 2023-08-14 16:16:21,454 >> The following columns in the test set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id. If offset_mapping, example_id are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2964] 2023-08-14 16:16:21,456 >> ***** Running Prediction *****\n",
            "[INFO|trainer.py:2966] 2023-08-14 16:16:21,456 >>   Num examples = 4772\n",
            "[INFO|trainer.py:2969] 2023-08-14 16:16:21,456 >>   Batch size = 8\n",
            "100% 597/597 [03:29<00:00,  3.35it/s]08/14/2023 16:19:58 - INFO - __main__ - Post-processing 1500 example predictions split into 4772 features.\n",
            "\n",
            "  0% 0/1500 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 9/1500 [00:00<00:17, 82.95it/s]\u001b[A\n",
            "  1% 19/1500 [00:00<00:16, 90.09it/s]\u001b[A\n",
            "  2% 30/1500 [00:00<00:15, 95.17it/s]\u001b[A\n",
            "  3% 41/1500 [00:00<00:15, 96.53it/s]\u001b[A\n",
            "  3% 51/1500 [00:00<00:15, 96.44it/s]\u001b[A\n",
            "  4% 61/1500 [00:00<00:15, 91.47it/s]\u001b[A\n",
            "  5% 71/1500 [00:00<00:15, 93.49it/s]\u001b[A\n",
            "  5% 81/1500 [00:00<00:15, 93.30it/s]\u001b[A\n",
            "  6% 92/1500 [00:00<00:14, 97.32it/s]\u001b[A\n",
            "  7% 102/1500 [00:01<00:15, 90.90it/s]\u001b[A\n",
            "  8% 116/1500 [00:01<00:13, 103.50it/s]\u001b[A\n",
            "  9% 129/1500 [00:01<00:12, 109.79it/s]\u001b[A\n",
            "  9% 141/1500 [00:01<00:12, 106.13it/s]\u001b[A\n",
            " 10% 154/1500 [00:01<00:12, 111.22it/s]\u001b[A\n",
            " 11% 166/1500 [00:01<00:12, 102.93it/s]\u001b[A\n",
            " 12% 177/1500 [00:01<00:13, 100.91it/s]\u001b[A\n",
            " 13% 188/1500 [00:01<00:13, 99.71it/s] \u001b[A\n",
            " 13% 200/1500 [00:02<00:12, 103.71it/s]\u001b[A\n",
            " 14% 211/1500 [00:02<00:12, 105.15it/s]\u001b[A\n",
            " 15% 222/1500 [00:02<00:14, 90.97it/s] \u001b[A\n",
            " 15% 232/1500 [00:02<00:14, 88.41it/s]\u001b[A\n",
            " 16% 242/1500 [00:02<00:13, 89.99it/s]\u001b[A\n",
            " 17% 254/1500 [00:02<00:12, 96.53it/s]\u001b[A\n",
            " 18% 264/1500 [00:02<00:13, 93.20it/s]\u001b[A\n",
            " 18% 277/1500 [00:02<00:12, 101.85it/s]\u001b[A\n",
            " 19% 288/1500 [00:02<00:11, 101.43it/s]\u001b[A\n",
            " 20% 299/1500 [00:03<00:12, 99.81it/s] \u001b[A\n",
            " 21% 310/1500 [00:03<00:11, 102.51it/s]\u001b[A\n",
            " 21% 322/1500 [00:03<00:10, 107.30it/s]\u001b[A\n",
            " 22% 333/1500 [00:03<00:11, 103.26it/s]\u001b[A\n",
            " 23% 344/1500 [00:03<00:11, 96.45it/s] \u001b[A\n",
            " 24% 356/1500 [00:03<00:11, 102.02it/s]\u001b[A\n",
            " 24% 367/1500 [00:03<00:10, 103.52it/s]\u001b[A\n",
            " 25% 378/1500 [00:03<00:12, 93.07it/s] \u001b[A\n",
            " 26% 388/1500 [00:03<00:12, 91.35it/s]\u001b[A\n",
            " 27% 399/1500 [00:04<00:11, 95.98it/s]\u001b[A\n",
            " 27% 410/1500 [00:04<00:11, 95.03it/s]\u001b[A\n",
            " 28% 420/1500 [00:04<00:11, 93.03it/s]\u001b[A\n",
            " 29% 430/1500 [00:04<00:12, 86.34it/s]\u001b[A\n",
            " 29% 439/1500 [00:04<00:12, 84.30it/s]\u001b[A\n",
            " 30% 448/1500 [00:04<00:15, 69.61it/s]\u001b[A\n",
            " 30% 456/1500 [00:04<00:17, 60.02it/s]\u001b[A\n",
            " 31% 463/1500 [00:05<00:16, 61.76it/s]\u001b[A\n",
            " 31% 470/1500 [00:05<00:17, 57.52it/s]\u001b[A\n",
            " 32% 477/1500 [00:05<00:18, 55.83it/s]\u001b[A\n",
            " 32% 483/1500 [00:05<00:19, 53.26it/s]\u001b[A\n",
            " 33% 489/1500 [00:05<00:20, 48.53it/s]\u001b[A\n",
            " 33% 494/1500 [00:05<00:20, 48.53it/s]\u001b[A\n",
            " 33% 499/1500 [00:05<00:20, 48.45it/s]\u001b[A\n",
            " 34% 505/1500 [00:05<00:20, 49.13it/s]\u001b[A\n",
            " 34% 510/1500 [00:06<00:20, 48.85it/s]\u001b[A\n",
            " 34% 516/1500 [00:06<00:19, 50.84it/s]\u001b[A\n",
            " 35% 522/1500 [00:06<00:19, 49.60it/s]\u001b[A\n",
            " 35% 528/1500 [00:06<00:19, 50.54it/s]\u001b[A\n",
            " 36% 534/1500 [00:06<00:18, 52.32it/s]\u001b[A\n",
            " 36% 540/1500 [00:06<00:18, 52.76it/s]\u001b[A\n",
            " 36% 546/1500 [00:06<00:18, 50.76it/s]\u001b[A\n",
            " 37% 552/1500 [00:06<00:18, 52.37it/s]\u001b[A\n",
            " 37% 558/1500 [00:06<00:18, 50.66it/s]\u001b[A\n",
            " 38% 564/1500 [00:07<00:19, 48.09it/s]\u001b[A\n",
            " 38% 569/1500 [00:07<00:19, 47.11it/s]\u001b[A\n",
            " 38% 575/1500 [00:07<00:18, 49.90it/s]\u001b[A\n",
            " 39% 582/1500 [00:07<00:16, 54.97it/s]\u001b[A\n",
            " 39% 588/1500 [00:07<00:17, 51.05it/s]\u001b[A\n",
            " 40% 596/1500 [00:07<00:15, 57.77it/s]\u001b[A\n",
            " 40% 604/1500 [00:07<00:15, 56.72it/s]\u001b[A\n",
            " 41% 612/1500 [00:07<00:15, 58.64it/s]\u001b[A\n",
            " 41% 618/1500 [00:08<00:15, 58.12it/s]\u001b[A\n",
            " 42% 624/1500 [00:08<00:15, 55.17it/s]\u001b[A\n",
            " 42% 630/1500 [00:08<00:15, 54.41it/s]\u001b[A\n",
            " 42% 637/1500 [00:08<00:15, 57.47it/s]\u001b[A\n",
            " 43% 643/1500 [00:08<00:16, 51.81it/s]\u001b[A\n",
            " 43% 649/1500 [00:08<00:16, 52.34it/s]\u001b[A\n",
            " 44% 657/1500 [00:08<00:14, 59.01it/s]\u001b[A\n",
            " 44% 665/1500 [00:08<00:13, 63.20it/s]\u001b[A\n",
            " 45% 673/1500 [00:08<00:13, 63.33it/s]\u001b[A\n",
            " 45% 681/1500 [00:09<00:12, 66.41it/s]\u001b[A\n",
            " 46% 688/1500 [00:09<00:13, 60.11it/s]\u001b[A\n",
            " 46% 695/1500 [00:09<00:12, 62.39it/s]\u001b[A\n",
            " 47% 702/1500 [00:09<00:12, 62.55it/s]\u001b[A\n",
            " 47% 709/1500 [00:09<00:13, 58.14it/s]\u001b[A\n",
            " 48% 715/1500 [00:09<00:15, 51.97it/s]\u001b[A\n",
            " 48% 722/1500 [00:09<00:14, 53.34it/s]\u001b[A\n",
            " 49% 729/1500 [00:09<00:13, 55.42it/s]\u001b[A\n",
            " 49% 735/1500 [00:10<00:15, 49.53it/s]\u001b[A\n",
            " 50% 743/1500 [00:10<00:13, 56.88it/s]\u001b[A\n",
            " 50% 753/1500 [00:10<00:11, 66.28it/s]\u001b[A\n",
            " 51% 764/1500 [00:10<00:09, 76.12it/s]\u001b[A\n",
            " 52% 774/1500 [00:10<00:08, 81.61it/s]\u001b[A\n",
            " 52% 783/1500 [00:10<00:08, 81.15it/s]\u001b[A\n",
            " 53% 795/1500 [00:10<00:07, 90.16it/s]\u001b[A\n",
            " 54% 806/1500 [00:10<00:07, 94.86it/s]\u001b[A\n",
            " 54% 816/1500 [00:10<00:07, 90.82it/s]\u001b[A\n",
            " 55% 826/1500 [00:11<00:07, 87.18it/s]\u001b[A\n",
            " 56% 838/1500 [00:11<00:06, 95.35it/s]\u001b[A\n",
            " 57% 848/1500 [00:11<00:06, 94.95it/s]\u001b[A\n",
            " 57% 858/1500 [00:11<00:07, 91.53it/s]\u001b[A\n",
            " 58% 868/1500 [00:11<00:06, 92.19it/s]\u001b[A\n",
            " 59% 878/1500 [00:11<00:06, 92.72it/s]\u001b[A\n",
            " 59% 888/1500 [00:11<00:06, 94.04it/s]\u001b[A\n",
            " 60% 898/1500 [00:11<00:06, 88.75it/s]\u001b[A\n",
            " 61% 910/1500 [00:11<00:06, 95.93it/s]\u001b[A\n",
            " 61% 921/1500 [00:12<00:06, 96.30it/s]\u001b[A\n",
            " 62% 932/1500 [00:12<00:05, 98.12it/s]\u001b[A\n",
            " 63% 942/1500 [00:12<00:05, 94.21it/s]\u001b[A\n",
            " 63% 952/1500 [00:12<00:05, 93.64it/s]\u001b[A\n",
            " 65% 968/1500 [00:12<00:04, 110.55it/s]\u001b[A\n",
            " 65% 980/1500 [00:12<00:05, 95.84it/s] \u001b[A\n",
            " 66% 990/1500 [00:12<00:05, 96.81it/s]\u001b[A\n",
            " 67% 1002/1500 [00:12<00:04, 102.86it/s]\u001b[A\n",
            " 68% 1013/1500 [00:13<00:04, 97.57it/s] \u001b[A\n",
            " 68% 1024/1500 [00:13<00:04, 97.40it/s]\u001b[A\n",
            " 69% 1034/1500 [00:13<00:04, 96.37it/s]\u001b[A\n",
            " 70% 1044/1500 [00:13<00:05, 90.90it/s]\u001b[A\n",
            " 70% 1054/1500 [00:13<00:04, 89.37it/s]\u001b[A\n",
            " 71% 1064/1500 [00:13<00:04, 90.13it/s]\u001b[A\n",
            " 72% 1075/1500 [00:13<00:04, 94.37it/s]\u001b[A\n",
            " 72% 1086/1500 [00:13<00:04, 96.65it/s]\u001b[A\n",
            " 73% 1097/1500 [00:13<00:04, 98.73it/s]\u001b[A\n",
            " 74% 1107/1500 [00:14<00:04, 95.64it/s]\u001b[A\n",
            " 74% 1117/1500 [00:14<00:03, 96.32it/s]\u001b[A\n",
            " 75% 1127/1500 [00:14<00:03, 96.17it/s]\u001b[A\n",
            " 76% 1137/1500 [00:14<00:03, 94.20it/s]\u001b[A\n",
            " 77% 1152/1500 [00:14<00:03, 109.52it/s]\u001b[A\n",
            " 78% 1164/1500 [00:14<00:03, 105.75it/s]\u001b[A\n",
            " 78% 1175/1500 [00:14<00:03, 97.76it/s] \u001b[A\n",
            " 79% 1188/1500 [00:14<00:03, 103.40it/s]\u001b[A\n",
            " 80% 1199/1500 [00:14<00:02, 102.80it/s]\u001b[A\n",
            " 81% 1210/1500 [00:15<00:02, 101.47it/s]\u001b[A\n",
            " 81% 1221/1500 [00:15<00:02, 102.76it/s]\u001b[A\n",
            " 82% 1232/1500 [00:15<00:02, 102.19it/s]\u001b[A\n",
            " 83% 1243/1500 [00:15<00:02, 93.97it/s] \u001b[A\n",
            " 84% 1253/1500 [00:15<00:02, 91.67it/s]\u001b[A\n",
            " 84% 1264/1500 [00:15<00:02, 95.24it/s]\u001b[A\n",
            " 85% 1274/1500 [00:15<00:02, 91.10it/s]\u001b[A\n",
            " 86% 1284/1500 [00:15<00:02, 89.93it/s]\u001b[A\n",
            " 86% 1294/1500 [00:15<00:02, 89.93it/s]\u001b[A\n",
            " 87% 1305/1500 [00:16<00:02, 95.19it/s]\u001b[A\n",
            " 88% 1315/1500 [00:16<00:01, 93.45it/s]\u001b[A\n",
            " 88% 1325/1500 [00:16<00:01, 93.91it/s]\u001b[A\n",
            " 89% 1337/1500 [00:16<00:01, 100.81it/s]\u001b[A\n",
            " 90% 1348/1500 [00:16<00:01, 96.97it/s] \u001b[A\n",
            " 91% 1358/1500 [00:16<00:01, 95.17it/s]\u001b[A\n",
            " 91% 1368/1500 [00:16<00:01, 89.70it/s]\u001b[A\n",
            " 92% 1378/1500 [00:16<00:01, 89.08it/s]\u001b[A\n",
            " 93% 1390/1500 [00:16<00:01, 94.49it/s]\u001b[A\n",
            " 93% 1400/1500 [00:17<00:01, 93.31it/s]\u001b[A\n",
            " 94% 1412/1500 [00:17<00:00, 100.18it/s]\u001b[A\n",
            " 95% 1423/1500 [00:17<00:00, 97.89it/s] \u001b[A\n",
            " 96% 1435/1500 [00:17<00:00, 102.50it/s]\u001b[A\n",
            " 96% 1446/1500 [00:17<00:00, 99.06it/s] \u001b[A\n",
            " 97% 1456/1500 [00:17<00:00, 95.55it/s]\u001b[A\n",
            " 98% 1466/1500 [00:17<00:00, 96.29it/s]\u001b[A\n",
            " 98% 1476/1500 [00:17<00:00, 92.94it/s]\u001b[A\n",
            " 99% 1489/1500 [00:17<00:00, 101.86it/s]\u001b[A\n",
            "100% 1500/1500 [00:18<00:00, 83.05it/s] \n",
            "08/14/2023 16:20:16 - INFO - __main__ - Saving predictions to drive/MyDrive/adapter_news_s1csqa_nl/predict_predictions.json.\n",
            "08/14/2023 16:20:16 - INFO - __main__ - Saving nbest_preds to drive/MyDrive/adapter_news_s1csqa_nl/predict_nbest_predictions.json.\n",
            "***** predict metrics *****\n",
            "  predict_samples         =       4772\n",
            "  test_exact_match        =     7.5333\n",
            "  test_f1                 =    55.9175\n",
            "  test_runtime            = 0:03:29.89\n",
            "  test_samples_per_second =     22.735\n",
            "  test_steps_per_second   =      2.844\n",
            "[INFO|modelcard.py:449] 2023-08-14 16:20:17,297 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n",
            "100% 597/597 [03:55<00:00,  2.53it/s]\n"
          ]
        }
      ],
      "source": [
        "!python drive/MyDrive/testqa4.py --model_name_or_path 'bert-base-uncased' --output_dir \"drive/MyDrive/adapter_news_s1csqa_nl\" --train_file \"drive/MyDrive/train_news.json\" --test_file \"drive/MyDrive/val_news.json\" --do_predict True --do_train True --overwrite_output_dir True --save_total_limit 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDHbZ6foLtaa",
        "outputId": "e10fee8e-0c85-4f0e-e060-18e189936008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "08/13/2023 14:06:14 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "08/13/2023 14:06:14 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=passive,\n",
            "log_on_each_node=True,\n",
            "logging_dir=drive/MyDrive/adapter_medical_fusion_squad2/runs/Aug13_14-06-14_2a7e7e9a27f8,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=drive/MyDrive/adapter_medical_fusion_squad2,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=drive/MyDrive/adapter_medical_fusion_squad2,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=None' instead.\n",
            "  warnings.warn(\n",
            "Using custom data configuration default-a1158a1433843231\n",
            "08/13/2023 14:06:14 - INFO - datasets.builder - Using custom data configuration default-a1158a1433843231\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "08/13/2023 14:06:14 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "Generating dataset json (/root/.cache/huggingface/datasets/json/default-a1158a1433843231/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
            "08/13/2023 14:06:14 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-a1158a1433843231/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-a1158a1433843231/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n",
            "08/13/2023 14:06:14 - INFO - datasets.builder - Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-a1158a1433843231/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n",
            "Downloading data files: 100% 2/2 [00:00<00:00, 4306.27it/s]\n",
            "Downloading took 0.0 min\n",
            "08/13/2023 14:06:14 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
            "Checksum Computation took 0.0 min\n",
            "08/13/2023 14:06:14 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
            "Extracting data files: 100% 2/2 [00:03<00:00,  1.54s/it]\n",
            "Generating train split\n",
            "08/13/2023 14:06:17 - INFO - datasets.builder - Generating train split\n",
            "Generating train split: 8000 examples [00:01, 7164.24 examples/s]\n",
            "Generating test split\n",
            "08/13/2023 14:06:19 - INFO - datasets.builder - Generating test split\n",
            "Generating test split: 1500 examples [00:00, 2741.73 examples/s]\n",
            "Unable to verify splits sizes.\n",
            "08/13/2023 14:06:19 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-a1158a1433843231/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n",
            "08/13/2023 14:06:19 - INFO - datasets.builder - Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-a1158a1433843231/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n",
            "Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 2.51MB/s]\n",
            "[INFO|configuration_utils.py:666] 2023-08-13 14:06:19,901 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/config.json\n",
            "[INFO|configuration_utils.py:718] 2023-08-13 14:06:19,905 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 181kB/s]\n",
            "[INFO|configuration_utils.py:666] 2023-08-13 14:06:20,103 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/config.json\n",
            "[INFO|configuration_utils.py:718] 2023-08-13 14:06:20,103 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 1.43MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 466k/466k [00:00<00:00, 2.83MB/s]\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-08-13 14:06:21,030 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-08-13 14:06:21,030 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-08-13 14:06:21,030 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-08-13 14:06:21,030 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-08-13 14:06:21,030 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/tokenizer_config.json\n",
            "[INFO|configuration_utils.py:666] 2023-08-13 14:06:21,031 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/config.json\n",
            "[INFO|configuration_utils.py:718] 2023-08-13 14:06:21,032 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Downloading pytorch_model.bin: 100% 440M/440M [00:01<00:00, 278MB/s]\n",
            "[INFO|modeling_utils.py:2275] 2023-08-13 14:06:22,866 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/1dbc166cf8765166998eff31ade2eb64c8a40076/pytorch_model.bin\n",
            "[WARNING|modeling_utils.py:2850] 2023-08-13 14:06:24,325 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2862] 2023-08-13 14:06:24,325 >> Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fetching 6 files:   0% 0/6 [00:00<?, ?it/s]\n",
            "Downloading (…)4ff9f/.gitattributes: 100% 1.18k/1.18k [00:00<00:00, 6.27MB/s]\n",
            "Fetching 6 files:  17% 1/6 [00:00<00:03,  1.50it/s]\n",
            "Downloading (…)f9f/head_config.json: 100% 338/338 [00:00<00:00, 1.54MB/s]\n",
            "\n",
            "Downloading (…)a99d54ff9f/README.md: 100% 2.24k/2.24k [00:00<00:00, 11.2MB/s]\n",
            "\n",
            "Downloading (…)/adapter_config.json: 100% 571/571 [00:00<00:00, 3.74MB/s]\n",
            "\n",
            "Downloading pytorch_model_head.bin: 100% 7.22k/7.22k [00:00<00:00, 24.8MB/s]\n",
            "\n",
            "Downloading pytorch_adapter.bin: 100% 3.59M/3.59M [00:00<00:00, 46.7MB/s]\n",
            "Fetching 6 files: 100% 6/6 [00:01<00:00,  4.54it/s]\n",
            "[INFO|loading.py:77] 2023-08-13 14:06:25,811 >> Loading module configuration from /root/.cache/huggingface/hub/models--AdapterHub--bert-base-uncased-pf-newsqa/snapshots/1d25a40c0cef2e4a090fd691da91bfa99d54ff9f/adapter_config.json\n",
            "[INFO|configuration.py:734] 2023-08-13 14:06:25,812 >> Adding adapter 'news_qa'.\n",
            "[INFO|loading.py:146] 2023-08-13 14:06:25,851 >> Loading module weights from /root/.cache/huggingface/hub/models--AdapterHub--bert-base-uncased-pf-newsqa/snapshots/1d25a40c0cef2e4a090fd691da91bfa99d54ff9f/pytorch_adapter.bin\n",
            "[INFO|loading.py:77] 2023-08-13 14:06:25,861 >> Loading module configuration from /root/.cache/huggingface/hub/models--AdapterHub--bert-base-uncased-pf-newsqa/snapshots/1d25a40c0cef2e4a090fd691da91bfa99d54ff9f/head_config.json\n",
            "[WARNING|loading.py:698] 2023-08-13 14:06:25,861 >> Model class 'BertModelWithHeads' of found prediction head does not match current model class.\n",
            "[INFO|utils.py:640] 2023-08-13 14:06:26,208 >> Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/squad2/bert-base-uncased/pfeiffer/bert-base-uncased_qa_squad2_pfeiffer.zip.\n",
            "[INFO|utils.py:313] 2023-08-13 14:06:26,438 >> https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/squad2/bert-base-uncased/pfeiffer/bert-base-uncased_qa_squad2_pfeiffer.zip not found in cache or force_download set to True, downloading to /content/~/.cache/torch/adapters/tmpvnynzwpb\n",
            "Downloading (…)_squad2_pfeiffer.zip: 100% 3.60M/3.60M [00:00<00:00, 46.3MB/s]\n",
            "[INFO|utils.py:323] 2023-08-13 14:06:26,725 >> storing https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/squad2/bert-base-uncased/pfeiffer/bert-base-uncased_qa_squad2_pfeiffer.zip in cache at ~/.cache/torch/adapters/b7a6f807b1206d5a9f5e5a8892b3a1c4c962c6613ad123ad4b7091908bd49de1.f927efc23a43a9b0bd88f155fbd499789805dc3429b31f1eddda0bd8aaf916ff\n",
            "[INFO|utils.py:331] 2023-08-13 14:06:26,725 >> creating metadata file for ~/.cache/torch/adapters/b7a6f807b1206d5a9f5e5a8892b3a1c4c962c6613ad123ad4b7091908bd49de1.f927efc23a43a9b0bd88f155fbd499789805dc3429b31f1eddda0bd8aaf916ff\n",
            "[INFO|loading.py:77] 2023-08-13 14:06:26,754 >> Loading module configuration from ~/.cache/torch/adapters/b7a6f807b1206d5a9f5e5a8892b3a1c4c962c6613ad123ad4b7091908bd49de1-f927efc23a43a9b0bd88f155fbd499789805dc3429b31f1eddda0bd8aaf916ff-extracted/adapter_config.json\n",
            "[INFO|configuration.py:734] 2023-08-13 14:06:26,754 >> Adding adapter 'squad2'.\n",
            "[INFO|loading.py:146] 2023-08-13 14:06:26,801 >> Loading module weights from ~/.cache/torch/adapters/b7a6f807b1206d5a9f5e5a8892b3a1c4c962c6613ad123ad4b7091908bd49de1-f927efc23a43a9b0bd88f155fbd499789805dc3429b31f1eddda0bd8aaf916ff-extracted/pytorch_adapter.bin\n",
            "[INFO|loading.py:164] 2023-08-13 14:06:26,815 >> Some module weights could not be found in loaded weights file: bert.invertible_adapters.squad2.F.0.weight, bert.invertible_adapters.squad2.F.0.bias, bert.invertible_adapters.squad2.F.2.weight, bert.invertible_adapters.squad2.F.2.bias, bert.invertible_adapters.squad2.G.0.weight, bert.invertible_adapters.squad2.G.0.bias, bert.invertible_adapters.squad2.G.2.weight, bert.invertible_adapters.squad2.G.2.bias\n",
            "[INFO|loading.py:77] 2023-08-13 14:06:26,815 >> Loading module configuration from ~/.cache/torch/adapters/b7a6f807b1206d5a9f5e5a8892b3a1c4c962c6613ad123ad4b7091908bd49de1-f927efc23a43a9b0bd88f155fbd499789805dc3429b31f1eddda0bd8aaf916ff-extracted/head_config.json\n",
            "[WARNING|loading.py:698] 2023-08-13 14:06:26,815 >> Model class 'BertModelWithHeads' of found prediction head does not match current model class.\n",
            "[INFO|configuration.py:783] 2023-08-13 14:06:26,815 >> Adding AdapterFusion 'news_qa,squad2'.\n",
            "Running tokenizer on train dataset:   0% 0/8000 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-a1158a1433843231/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-4cbd397f3647856f.arrow\n",
            "08/13/2023 14:06:32 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-a1158a1433843231/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-4cbd397f3647856f.arrow\n",
            "Running tokenizer on train dataset: 100% 8000/8000 [00:41<00:00, 190.69 examples/s]\n",
            "Running tokenizer on prediction dataset:   0% 0/1500 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-a1158a1433843231/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-8a74e48a4c52ed46.arrow\n",
            "08/13/2023 14:07:16 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-a1158a1433843231/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-8a74e48a4c52ed46.arrow\n",
            "Running tokenizer on prediction dataset: 100% 1500/1500 [00:11<00:00, 125.69 examples/s]\n",
            "Downloading builder script: 100% 4.53k/4.53k [00:00<00:00, 16.6MB/s]\n",
            "Downloading extra modules: 100% 3.32k/3.32k [00:00<00:00, 14.9MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1650] 2023-08-13 14:07:27,497 >> ***** Running training *****\n",
            "[INFO|trainer.py:1651] 2023-08-13 14:07:27,497 >>   Num examples = 40139\n",
            "[INFO|trainer.py:1652] 2023-08-13 14:07:27,497 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1653] 2023-08-13 14:07:27,497 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:1654] 2023-08-13 14:07:27,497 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer.py:1655] 2023-08-13 14:07:27,497 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1656] 2023-08-13 14:07:27,497 >>   Total optimization steps = 15054\n",
            "[INFO|trainer.py:1657] 2023-08-13 14:07:27,500 >>   Number of trainable parameters = 21253634\n",
            "{'loss': 1.186, 'learning_rate': 4.8339311810814404e-05, 'epoch': 0.1}\n",
            "  3% 500/15054 [05:26<2:39:20,  1.52it/s][INFO|trainer.py:141] 2023-08-13 14:12:53,906 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500\n",
            "[INFO|loading.py:60] 2023-08-13 14:12:53,912 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:12:53,942 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:12:53,946 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:12:53,955 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:12:53,961 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:12:53,986 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:12:53,990 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:12:53,999 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:12:54,005 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:12:54,206 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 14:12:54,211 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 14:12:54,214 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 0.9521, 'learning_rate': 4.66786236216288e-05, 'epoch': 0.2}\n",
            "  7% 1000/15054 [10:56<2:34:45,  1.51it/s][INFO|trainer.py:141] 2023-08-13 14:18:23,625 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000\n",
            "[INFO|loading.py:60] 2023-08-13 14:18:23,630 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:18:23,663 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:18:23,668 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:18:23,681 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:18:23,686 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:18:23,718 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:18:23,722 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:18:23,732 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:18:23,739 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:18:24,007 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 14:18:24,014 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 14:18:24,031 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000/special_tokens_map.json\n",
            "{'loss': 0.886, 'learning_rate': 4.501793543244321e-05, 'epoch': 0.3}\n",
            " 10% 1500/15054 [16:26<2:28:06,  1.53it/s][INFO|trainer.py:141] 2023-08-13 14:23:53,914 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500\n",
            "[INFO|loading.py:60] 2023-08-13 14:23:53,920 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:23:53,946 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:23:53,950 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:23:53,958 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:23:53,964 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:23:54,007 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:23:54,012 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:23:54,019 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:23:54,026 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:23:54,218 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 14:23:54,222 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 14:23:54,226 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 14:23:54,865 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-500] due to args.save_total_limit\n",
            "{'loss': 0.874, 'learning_rate': 4.335724724325761e-05, 'epoch': 0.4}\n",
            " 13% 2000/15054 [21:55<2:23:53,  1.51it/s][INFO|trainer.py:141] 2023-08-13 14:29:23,189 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000\n",
            "[INFO|loading.py:60] 2023-08-13 14:29:23,194 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:29:23,226 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:29:23,230 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:29:23,240 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:29:23,245 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:29:23,273 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:29:23,277 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:29:23,286 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:29:23,291 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:29:23,541 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 14:29:23,546 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 14:29:23,550 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 14:29:24,396 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1000] due to args.save_total_limit\n",
            "{'loss': 0.8542, 'learning_rate': 4.169655905407201e-05, 'epoch': 0.5}\n",
            " 17% 2500/15054 [27:24<2:16:58,  1.53it/s][INFO|trainer.py:141] 2023-08-13 14:34:52,364 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500\n",
            "[INFO|loading.py:60] 2023-08-13 14:34:52,369 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:34:52,396 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:34:52,400 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:34:52,408 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:34:52,414 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:34:52,439 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:34:52,443 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:34:52,452 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:34:52,457 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:34:52,652 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 14:34:52,656 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 14:34:52,660 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 14:34:53,273 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-1500] due to args.save_total_limit\n",
            "{'loss': 0.8905, 'learning_rate': 4.003587086488641e-05, 'epoch': 0.6}\n",
            " 20% 3000/15054 [32:54<2:13:42,  1.50it/s][INFO|trainer.py:141] 2023-08-13 14:40:22,270 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000\n",
            "[INFO|loading.py:60] 2023-08-13 14:40:22,275 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:40:22,306 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:40:22,310 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:40:22,319 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:40:22,327 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:40:22,364 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:40:22,381 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:40:22,393 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:40:22,399 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:40:22,655 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 14:40:22,660 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 14:40:22,665 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 14:40:23,408 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2000] due to args.save_total_limit\n",
            "{'loss': 0.8458, 'learning_rate': 3.837518267570081e-05, 'epoch': 0.7}\n",
            " 23% 3500/15054 [38:23<2:05:23,  1.54it/s][INFO|trainer.py:141] 2023-08-13 14:45:51,065 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500\n",
            "[INFO|loading.py:60] 2023-08-13 14:45:51,070 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:45:51,097 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:45:51,102 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:45:51,112 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:45:51,117 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:45:51,143 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:45:51,147 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:45:51,156 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:45:51,161 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:45:51,362 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 14:45:51,372 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 14:45:51,404 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 14:45:52,014 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-2500] due to args.save_total_limit\n",
            "{'loss': 0.8357, 'learning_rate': 3.671449448651522e-05, 'epoch': 0.8}\n",
            " 27% 4000/15054 [43:52<2:00:41,  1.53it/s][INFO|trainer.py:141] 2023-08-13 14:51:19,696 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000\n",
            "[INFO|loading.py:60] 2023-08-13 14:51:19,702 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:51:19,733 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:51:19,737 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:51:19,747 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:51:19,753 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:51:19,782 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:51:19,786 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:51:19,796 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:51:19,802 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:51:20,057 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 14:51:20,073 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 14:51:20,091 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 14:51:21,402 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3000] due to args.save_total_limit\n",
            "{'loss': 0.8513, 'learning_rate': 3.5053806297329614e-05, 'epoch': 0.9}\n",
            " 30% 4500/15054 [49:21<1:55:11,  1.53it/s][INFO|trainer.py:141] 2023-08-13 14:56:48,583 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500\n",
            "[INFO|loading.py:60] 2023-08-13 14:56:48,589 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:56:48,615 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:56:48,618 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:56:48,626 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:56:48,632 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:56:48,658 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:56:48,662 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:56:48,670 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 14:56:48,675 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 14:56:48,874 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 14:56:48,880 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 14:56:48,893 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 14:56:49,498 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-3500] due to args.save_total_limit\n",
            "{'loss': 0.7941, 'learning_rate': 3.3393118108144016e-05, 'epoch': 1.0}\n",
            " 33% 5000/15054 [54:50<1:50:04,  1.52it/s][INFO|trainer.py:141] 2023-08-13 15:02:17,699 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000\n",
            "[INFO|loading.py:60] 2023-08-13 15:02:17,704 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:02:17,734 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:02:17,738 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:02:17,762 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:02:17,767 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:02:17,797 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:02:17,801 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:02:17,810 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:02:17,816 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:02:18,055 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 15:02:18,060 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 15:02:18,063 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 15:02:18,891 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4000] due to args.save_total_limit\n",
            "{'loss': 0.8055, 'learning_rate': 3.173242991895842e-05, 'epoch': 1.1}\n",
            " 37% 5500/15054 [1:00:18<1:43:37,  1.54it/s][INFO|trainer.py:141] 2023-08-13 15:07:46,302 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500\n",
            "[INFO|loading.py:60] 2023-08-13 15:07:46,308 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:07:46,334 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:07:46,337 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:07:46,346 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:07:46,351 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:07:46,376 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:07:46,380 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:07:46,399 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:07:46,406 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:07:46,614 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 15:07:46,618 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 15:07:46,622 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 15:07:47,191 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-4500] due to args.save_total_limit\n",
            "{'loss': 0.8331, 'learning_rate': 3.0071741729772817e-05, 'epoch': 1.2}\n",
            " 40% 6000/15054 [1:05:46<1:37:33,  1.55it/s][INFO|trainer.py:141] 2023-08-13 15:13:13,686 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000\n",
            "[INFO|loading.py:60] 2023-08-13 15:13:13,691 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:13:13,717 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:13:13,721 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:13:13,730 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:13:13,736 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:13:13,764 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:13:13,769 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:13:13,778 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:13:13,784 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:13:13,994 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 15:13:14,000 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 15:13:14,004 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 15:13:14,717 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5000] due to args.save_total_limit\n",
            "{'loss': 0.8465, 'learning_rate': 2.841105354058722e-05, 'epoch': 1.3}\n",
            " 43% 6500/15054 [1:11:13<1:32:41,  1.54it/s][INFO|trainer.py:141] 2023-08-13 15:18:41,249 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500\n",
            "[INFO|loading.py:60] 2023-08-13 15:18:41,255 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:18:41,282 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:18:41,285 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:18:41,294 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:18:41,299 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:18:41,325 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:18:41,329 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:18:41,336 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:18:41,343 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:18:41,558 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 15:18:41,563 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 15:18:41,576 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 15:18:42,204 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-5500] due to args.save_total_limit\n",
            "{'loss': 0.7938, 'learning_rate': 2.6750365351401625e-05, 'epoch': 1.39}\n",
            " 46% 7000/15054 [1:16:41<1:27:16,  1.54it/s][INFO|trainer.py:141] 2023-08-13 15:24:09,118 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000\n",
            "[INFO|loading.py:60] 2023-08-13 15:24:09,124 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:24:09,156 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:24:09,160 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:24:09,170 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:24:09,175 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:24:09,205 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:24:09,226 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:24:09,236 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:24:09,241 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:24:09,495 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 15:24:09,500 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 15:24:09,504 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 15:24:10,346 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6000] due to args.save_total_limit\n",
            "{'loss': 0.7894, 'learning_rate': 2.5089677162216024e-05, 'epoch': 1.49}\n",
            " 50% 7500/15054 [1:22:09<1:21:57,  1.54it/s][INFO|trainer.py:141] 2023-08-13 15:29:37,012 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500\n",
            "[INFO|loading.py:60] 2023-08-13 15:29:37,018 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:29:37,050 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:29:37,054 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:29:37,064 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:29:37,069 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:29:37,096 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:29:37,099 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:29:37,107 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:29:37,113 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:29:37,322 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 15:29:37,326 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 15:29:37,344 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 15:29:37,933 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-6500] due to args.save_total_limit\n",
            "{'loss': 0.7898, 'learning_rate': 2.3428988973030426e-05, 'epoch': 1.59}\n",
            " 53% 8000/15054 [1:27:36<1:17:33,  1.52it/s][INFO|trainer.py:141] 2023-08-13 15:35:04,106 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000\n",
            "[INFO|loading.py:60] 2023-08-13 15:35:04,117 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:35:04,155 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:35:04,160 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:35:04,172 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:35:04,178 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:35:04,209 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:35:04,213 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:35:04,223 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:35:04,229 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:35:04,495 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 15:35:04,510 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 15:35:04,520 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 15:35:05,828 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7000] due to args.save_total_limit\n",
            "{'loss': 0.8203, 'learning_rate': 2.1768300783844824e-05, 'epoch': 1.69}\n",
            " 56% 8500/15054 [1:33:04<1:10:50,  1.54it/s][INFO|trainer.py:141] 2023-08-13 15:40:32,017 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500\n",
            "[INFO|loading.py:60] 2023-08-13 15:40:32,022 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:40:32,050 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:40:32,054 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:40:32,063 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:40:32,084 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:40:32,111 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:40:32,115 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:40:32,124 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:40:32,129 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:40:32,341 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 15:40:32,345 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 15:40:32,348 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 15:40:32,997 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-7500] due to args.save_total_limit\n",
            "{'loss': 0.7951, 'learning_rate': 2.0107612594659226e-05, 'epoch': 1.79}\n",
            " 60% 9000/15054 [1:38:32<1:06:40,  1.51it/s][INFO|trainer.py:141] 2023-08-13 15:46:00,245 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000\n",
            "[INFO|loading.py:60] 2023-08-13 15:46:00,251 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:46:00,282 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:46:00,286 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:46:00,297 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:46:00,303 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:46:00,333 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:46:00,337 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:46:00,360 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:46:00,366 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:46:00,611 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 15:46:00,618 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 15:46:00,621 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 15:46:01,437 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8000] due to args.save_total_limit\n",
            "{'loss': 0.7902, 'learning_rate': 1.844692440547363e-05, 'epoch': 1.89}\n",
            " 63% 9500/15054 [1:44:00<59:52,  1.55it/s][INFO|trainer.py:141] 2023-08-13 15:51:28,201 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500\n",
            "[INFO|loading.py:60] 2023-08-13 15:51:28,206 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:51:28,234 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:51:28,238 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:51:28,246 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:51:28,251 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:51:28,277 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:51:28,282 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:51:28,289 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:51:28,294 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:51:28,511 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 15:51:28,516 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 15:51:28,520 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 15:51:29,096 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-8500] due to args.save_total_limit\n",
            "{'loss': 0.7515, 'learning_rate': 1.678623621628803e-05, 'epoch': 1.99}\n",
            " 66% 10000/15054 [1:49:27<54:58,  1.53it/s][INFO|trainer.py:141] 2023-08-13 15:56:55,171 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000\n",
            "[INFO|loading.py:60] 2023-08-13 15:56:55,177 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:56:55,204 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:56:55,207 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:56:55,215 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:56:55,220 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:56:55,246 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:56:55,251 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:56:55,258 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 15:56:55,264 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 15:56:55,478 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 15:56:55,483 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 15:56:55,486 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 15:56:56,296 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9000] due to args.save_total_limit\n",
            "{'loss': 0.7881, 'learning_rate': 1.5125548027102433e-05, 'epoch': 2.09}\n",
            " 70% 10500/15054 [1:54:54<49:19,  1.54it/s][INFO|trainer.py:141] 2023-08-13 16:02:22,025 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500\n",
            "[INFO|loading.py:60] 2023-08-13 16:02:22,031 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:02:22,063 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:02:22,067 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:02:22,078 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:02:22,083 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:02:22,113 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:02:22,118 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:02:22,128 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:02:22,134 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:02:22,445 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 16:02:22,453 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 16:02:22,457 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 16:02:23,753 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-9500] due to args.save_total_limit\n",
            "{'loss': 0.7638, 'learning_rate': 1.3464859837916833e-05, 'epoch': 2.19}\n",
            " 73% 11000/15054 [2:00:21<43:56,  1.54it/s][INFO|trainer.py:141] 2023-08-13 16:07:49,508 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000\n",
            "[INFO|loading.py:60] 2023-08-13 16:07:49,514 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:07:49,542 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:07:49,545 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:07:49,553 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:07:49,573 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:07:49,602 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:07:49,606 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:07:49,615 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:07:49,620 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:07:49,840 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 16:07:49,845 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 16:07:49,848 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 16:07:50,447 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10000] due to args.save_total_limit\n",
            "{'loss': 0.7246, 'learning_rate': 1.1804171648731235e-05, 'epoch': 2.29}\n",
            " 76% 11500/15054 [2:05:49<39:02,  1.52it/s][INFO|trainer.py:141] 2023-08-13 16:13:17,076 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500\n",
            "[INFO|loading.py:60] 2023-08-13 16:13:17,083 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:13:17,110 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:13:17,114 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:13:17,122 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:13:17,128 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:13:17,154 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:13:17,158 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:13:17,166 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:13:17,172 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:13:17,402 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 16:13:17,531 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 16:13:17,535 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 16:13:18,079 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-10500] due to args.save_total_limit\n",
            "{'loss': 0.7734, 'learning_rate': 1.0143483459545636e-05, 'epoch': 2.39}\n",
            " 80% 12000/15054 [2:11:17<32:57,  1.54it/s][INFO|trainer.py:141] 2023-08-13 16:18:44,610 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000\n",
            "[INFO|loading.py:60] 2023-08-13 16:18:44,615 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:18:44,642 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:18:44,645 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:18:44,654 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:18:44,659 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:18:44,685 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:18:44,689 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:18:44,698 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:18:44,704 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:18:44,913 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 16:18:44,919 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 16:18:44,923 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 16:18:45,811 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11000] due to args.save_total_limit\n",
            "{'loss': 0.7401, 'learning_rate': 8.482795270360038e-06, 'epoch': 2.49}\n",
            " 83% 12500/15054 [2:16:44<27:34,  1.54it/s][INFO|trainer.py:141] 2023-08-13 16:24:12,060 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500\n",
            "[INFO|loading.py:60] 2023-08-13 16:24:12,079 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:24:12,108 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:24:12,112 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:24:12,121 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:24:12,127 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:24:12,152 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:24:12,156 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:24:12,165 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:24:12,171 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:24:12,391 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 16:24:12,396 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 16:24:12,400 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 16:24:13,016 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-11500] due to args.save_total_limit\n",
            "{'loss': 0.7767, 'learning_rate': 6.822107081174439e-06, 'epoch': 2.59}\n",
            " 86% 13000/15054 [2:22:12<22:26,  1.53it/s][INFO|trainer.py:141] 2023-08-13 16:29:39,567 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000\n",
            "[INFO|loading.py:60] 2023-08-13 16:29:39,573 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:29:39,604 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:29:39,608 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:29:39,618 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:29:39,641 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:29:39,671 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:29:39,674 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:29:39,684 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:29:39,689 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:29:39,934 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 16:29:39,938 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 16:29:39,942 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 16:29:40,711 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12000] due to args.save_total_limit\n",
            "{'loss': 0.7828, 'learning_rate': 5.16141889198884e-06, 'epoch': 2.69}\n",
            " 90% 13500/15054 [2:27:39<16:47,  1.54it/s][INFO|trainer.py:141] 2023-08-13 16:35:07,354 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500\n",
            "[INFO|loading.py:60] 2023-08-13 16:35:07,360 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:35:07,388 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:35:07,391 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:35:07,401 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:35:07,407 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:35:07,433 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:35:07,437 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:35:07,446 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:35:07,452 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:35:07,672 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 16:35:07,680 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 16:35:07,711 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 16:35:08,312 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-12500] due to args.save_total_limit\n",
            "{'loss': 0.7522, 'learning_rate': 3.500730702803242e-06, 'epoch': 2.79}\n",
            " 93% 14000/15054 [2:33:07<11:25,  1.54it/s][INFO|trainer.py:141] 2023-08-13 16:40:34,853 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000\n",
            "[INFO|loading.py:60] 2023-08-13 16:40:34,859 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:40:34,887 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:40:34,890 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:40:34,899 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:40:34,905 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:40:34,930 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:40:34,934 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:40:34,942 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:40:34,949 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:40:35,158 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 16:40:35,163 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 16:40:35,166 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 16:40:35,967 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13000] due to args.save_total_limit\n",
            "{'loss': 0.7249, 'learning_rate': 1.8400425136176434e-06, 'epoch': 2.89}\n",
            " 96% 14500/15054 [2:38:34<06:01,  1.53it/s][INFO|trainer.py:141] 2023-08-13 16:46:02,205 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500\n",
            "[INFO|loading.py:60] 2023-08-13 16:46:02,211 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:46:02,246 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:46:02,251 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:46:02,273 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:46:02,278 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:46:02,314 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:46:02,319 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:46:02,329 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:46:02,334 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:46:02,592 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 16:46:02,609 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 16:46:02,616 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14500/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 16:46:03,455 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-13500] due to args.save_total_limit\n",
            "{'loss': 0.7489, 'learning_rate': 1.7935432443204466e-07, 'epoch': 2.99}\n",
            "100% 15000/15054 [2:44:02<00:35,  1.54it/s][INFO|trainer.py:141] 2023-08-13 16:51:29,718 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000\n",
            "[INFO|loading.py:60] 2023-08-13 16:51:29,723 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:51:29,752 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:51:29,755 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:51:29,763 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:51:29,769 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:51:29,796 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:51:29,800 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:51:29,809 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:51:29,815 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:51:30,038 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 16:51:30,044 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 16:51:30,048 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-15000/special_tokens_map.json\n",
            "[INFO|trainer.py:2787] 2023-08-13 16:51:30,831 >> Deleting older checkpoint [drive/MyDrive/adapter_medical_fusion_squad2/checkpoint-14000] due to args.save_total_limit\n",
            "100% 15054/15054 [2:44:38<00:00,  1.85it/s][INFO|trainer.py:1901] 2023-08-13 16:52:05,689 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 9878.1894, 'train_samples_per_second': 12.19, 'train_steps_per_second': 1.524, 'train_loss': 0.818297760062473, 'epoch': 3.0}\n",
            "100% 15054/15054 [2:44:38<00:00,  1.52it/s]\n",
            "[INFO|trainer.py:141] 2023-08-13 16:52:05,728 >> Saving model checkpoint to drive/MyDrive/adapter_medical_fusion_squad2\n",
            "[INFO|loading.py:60] 2023-08-13 16:52:05,737 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:52:05,773 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:52:05,777 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:52:05,786 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:52:05,793 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:52:05,830 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:52:05,834 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:52:05,844 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/squad2/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:52:05,851 >> Configuration saved in drive/MyDrive/adapter_medical_fusion_squad2/news_qa,squad2/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:52:06,130 >> Module weights saved in drive/MyDrive/adapter_medical_fusion_squad2/news_qa,squad2/pytorch_model_adapter_fusion.bin\n",
            "[INFO|tokenization_utils_base.py:2160] 2023-08-13 16:52:06,136 >> tokenizer config file saved in drive/MyDrive/adapter_medical_fusion_squad2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2167] 2023-08-13 16:52:06,146 >> Special tokens file saved in drive/MyDrive/adapter_medical_fusion_squad2/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =     0.8183\n",
            "  train_runtime            = 2:44:38.18\n",
            "  train_samples            =      40139\n",
            "  train_samples_per_second =      12.19\n",
            "  train_steps_per_second   =      1.524\n",
            "[INFO|loading.py:60] 2023-08-13 16:52:06,603 >> Configuration saved in drive/MyDrive/adapter_fusion_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:52:06,904 >> Module weights saved in drive/MyDrive/pytorch_model_adapter_fusion.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:52:06,911 >> Configuration saved in drive/MyDrive/news_qa/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:52:06,943 >> Module weights saved in drive/MyDrive/news_qa/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:52:06,946 >> Configuration saved in drive/MyDrive/news_qa/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:52:06,956 >> Module weights saved in drive/MyDrive/news_qa/pytorch_model_head.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:52:06,962 >> Configuration saved in drive/MyDrive/squad2/adapter_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:52:06,996 >> Module weights saved in drive/MyDrive/squad2/pytorch_adapter.bin\n",
            "[INFO|loading.py:60] 2023-08-13 16:52:07,000 >> Configuration saved in drive/MyDrive/squad2/head_config.json\n",
            "[INFO|loading.py:73] 2023-08-13 16:52:07,012 >> Module weights saved in drive/MyDrive/squad2/pytorch_model_head.bin\n",
            "08/13/2023 16:52:07 - INFO - __main__ - *** Predict ***\n",
            "[INFO|trainer.py:710] 2023-08-13 16:52:07,012 >> The following columns in the test set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id. If offset_mapping, example_id are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2964] 2023-08-13 16:52:07,015 >> ***** Running Prediction *****\n",
            "[INFO|trainer.py:2966] 2023-08-13 16:52:07,015 >>   Num examples = 8500\n",
            "[INFO|trainer.py:2969] 2023-08-13 16:52:07,015 >>   Batch size = 8\n",
            "100% 1063/1063 [05:13<00:00,  4.00it/s]08/13/2023 16:57:33 - INFO - __main__ - Post-processing 1500 example predictions split into 8500 features.\n",
            "\n",
            "  0% 0/1500 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 4/1500 [00:00<00:39, 37.74it/s]\u001b[A\n",
            "  1% 10/1500 [00:00<00:32, 45.37it/s]\u001b[A\n",
            "  1% 15/1500 [00:00<01:01, 24.12it/s]\u001b[A\n",
            "  1% 20/1500 [00:00<00:49, 30.05it/s]\u001b[A\n",
            "  2% 24/1500 [00:00<01:04, 23.01it/s]\u001b[A\n",
            "  2% 28/1500 [00:01<01:01, 24.08it/s]\u001b[A\n",
            "  2% 32/1500 [00:01<00:57, 25.38it/s]\u001b[A\n",
            "  2% 35/1500 [00:01<00:55, 26.34it/s]\u001b[A\n",
            "  3% 39/1500 [00:01<00:49, 29.44it/s]\u001b[A\n",
            "  3% 43/1500 [00:01<00:49, 29.17it/s]\u001b[A\n",
            "  3% 49/1500 [00:01<00:48, 29.91it/s]\u001b[A\n",
            "  4% 54/1500 [00:01<00:42, 34.01it/s]\u001b[A\n",
            "  4% 59/1500 [00:01<00:39, 36.89it/s]\u001b[A\n",
            "  4% 64/1500 [00:02<00:37, 38.59it/s]\u001b[A\n",
            "  5% 69/1500 [00:02<00:36, 39.71it/s]\u001b[A\n",
            "  5% 74/1500 [00:02<00:50, 28.38it/s]\u001b[A\n",
            "  5% 81/1500 [00:02<00:39, 35.82it/s]\u001b[A\n",
            "  6% 87/1500 [00:02<00:35, 39.67it/s]\u001b[A\n",
            "  6% 92/1500 [00:02<00:37, 37.54it/s]\u001b[A\n",
            "  6% 97/1500 [00:02<00:34, 40.15it/s]\u001b[A\n",
            "  7% 103/1500 [00:03<00:34, 40.50it/s]\u001b[A\n",
            "  7% 108/1500 [00:03<00:35, 39.15it/s]\u001b[A\n",
            "  8% 113/1500 [00:03<00:33, 41.48it/s]\u001b[A\n",
            "  8% 118/1500 [00:03<00:32, 42.73it/s]\u001b[A\n",
            "  8% 123/1500 [00:03<00:31, 44.00it/s]\u001b[A\n",
            "  9% 128/1500 [00:03<00:33, 41.45it/s]\u001b[A\n",
            "  9% 134/1500 [00:03<00:30, 44.67it/s]\u001b[A\n",
            "  9% 141/1500 [00:03<00:26, 51.08it/s]\u001b[A\n",
            " 10% 150/1500 [00:04<00:22, 60.96it/s]\u001b[A\n",
            " 10% 157/1500 [00:04<00:40, 33.38it/s]\u001b[A\n",
            " 11% 164/1500 [00:04<00:37, 35.81it/s]\u001b[A\n",
            " 11% 172/1500 [00:04<00:30, 43.83it/s]\u001b[A\n",
            " 12% 178/1500 [00:04<00:31, 42.63it/s]\u001b[A\n",
            " 12% 187/1500 [00:04<00:25, 52.16it/s]\u001b[A\n",
            " 13% 197/1500 [00:05<00:21, 60.25it/s]\u001b[A\n",
            " 14% 206/1500 [00:05<00:19, 67.21it/s]\u001b[A\n",
            " 14% 214/1500 [00:05<00:27, 47.35it/s]\u001b[A\n",
            " 15% 223/1500 [00:05<00:23, 55.28it/s]\u001b[A\n",
            " 15% 231/1500 [00:05<00:21, 60.02it/s]\u001b[A\n",
            " 16% 239/1500 [00:05<00:23, 53.58it/s]\u001b[A\n",
            " 16% 246/1500 [00:06<00:25, 48.86it/s]\u001b[A\n",
            " 17% 252/1500 [00:06<00:31, 39.26it/s]\u001b[A\n",
            " 17% 262/1500 [00:06<00:25, 49.48it/s]\u001b[A\n",
            " 18% 268/1500 [00:06<00:32, 38.36it/s]\u001b[A\n",
            " 18% 273/1500 [00:06<00:34, 36.01it/s]\u001b[A\n",
            " 19% 279/1500 [00:06<00:30, 40.37it/s]\u001b[A\n",
            " 19% 288/1500 [00:07<00:24, 49.03it/s]\u001b[A\n",
            " 20% 294/1500 [00:07<00:24, 49.30it/s]\u001b[A\n",
            " 20% 300/1500 [00:07<00:28, 42.77it/s]\u001b[A\n",
            " 20% 305/1500 [00:07<00:30, 38.66it/s]\u001b[A\n",
            " 21% 312/1500 [00:07<00:26, 44.84it/s]\u001b[A\n",
            " 21% 318/1500 [00:07<00:24, 47.97it/s]\u001b[A\n",
            " 22% 326/1500 [00:07<00:21, 55.34it/s]\u001b[A\n",
            " 22% 332/1500 [00:08<00:26, 44.43it/s]\u001b[A\n",
            " 23% 339/1500 [00:08<00:23, 48.65it/s]\u001b[A\n",
            " 23% 345/1500 [00:08<00:22, 51.10it/s]\u001b[A\n",
            " 24% 353/1500 [00:08<00:19, 57.41it/s]\u001b[A\n",
            " 24% 362/1500 [00:08<00:17, 64.85it/s]\u001b[A\n",
            " 25% 369/1500 [00:08<00:21, 52.35it/s]\u001b[A\n",
            " 25% 376/1500 [00:08<00:20, 55.75it/s]\u001b[A\n",
            " 26% 383/1500 [00:08<00:21, 51.88it/s]\u001b[A\n",
            " 26% 389/1500 [00:09<00:20, 53.56it/s]\u001b[A\n",
            " 27% 398/1500 [00:09<00:18, 60.52it/s]\u001b[A\n",
            " 27% 405/1500 [00:09<00:17, 61.09it/s]\u001b[A\n",
            " 27% 412/1500 [00:09<00:25, 42.42it/s]\u001b[A\n",
            " 28% 419/1500 [00:09<00:22, 47.34it/s]\u001b[A\n",
            " 28% 425/1500 [00:09<00:24, 43.84it/s]\u001b[A\n",
            " 29% 432/1500 [00:09<00:22, 48.34it/s]\u001b[A\n",
            " 29% 440/1500 [00:10<00:22, 46.64it/s]\u001b[A\n",
            " 30% 446/1500 [00:10<00:21, 49.00it/s]\u001b[A\n",
            " 30% 456/1500 [00:10<00:17, 60.37it/s]\u001b[A\n",
            " 31% 463/1500 [00:10<00:18, 57.08it/s]\u001b[A\n",
            " 31% 472/1500 [00:10<00:16, 62.40it/s]\u001b[A\n",
            " 32% 480/1500 [00:10<00:15, 66.78it/s]\u001b[A\n",
            " 32% 487/1500 [00:10<00:15, 66.46it/s]\u001b[A\n",
            " 33% 495/1500 [00:10<00:14, 69.32it/s]\u001b[A\n",
            " 34% 503/1500 [00:11<00:17, 56.10it/s]\u001b[A\n",
            " 34% 510/1500 [00:11<00:19, 51.19it/s]\u001b[A\n",
            " 34% 517/1500 [00:11<00:18, 54.16it/s]\u001b[A\n",
            " 35% 526/1500 [00:11<00:16, 60.58it/s]\u001b[A\n",
            " 36% 533/1500 [00:11<00:15, 61.35it/s]\u001b[A\n",
            " 36% 543/1500 [00:11<00:13, 69.14it/s]\u001b[A\n",
            " 37% 551/1500 [00:11<00:15, 60.40it/s]\u001b[A\n",
            " 37% 558/1500 [00:12<00:15, 61.29it/s]\u001b[A\n",
            " 38% 567/1500 [00:12<00:14, 65.58it/s]\u001b[A\n",
            " 38% 574/1500 [00:12<00:14, 63.85it/s]\u001b[A\n",
            " 39% 581/1500 [00:12<00:17, 53.15it/s]\u001b[A\n",
            " 39% 587/1500 [00:12<00:22, 40.21it/s]\u001b[A\n",
            " 39% 592/1500 [00:12<00:26, 33.68it/s]\u001b[A\n",
            " 40% 600/1500 [00:13<00:21, 41.71it/s]\u001b[A\n",
            " 40% 606/1500 [00:13<00:22, 39.62it/s]\u001b[A\n",
            " 41% 614/1500 [00:13<00:19, 46.03it/s]\u001b[A\n",
            " 41% 620/1500 [00:13<00:18, 48.51it/s]\u001b[A\n",
            " 42% 627/1500 [00:13<00:19, 45.82it/s]\u001b[A\n",
            " 42% 637/1500 [00:13<00:15, 56.66it/s]\u001b[A\n",
            " 43% 644/1500 [00:14<00:26, 32.15it/s]\u001b[A\n",
            " 43% 649/1500 [00:14<00:33, 25.68it/s]\u001b[A\n",
            " 44% 654/1500 [00:14<00:30, 27.93it/s]\u001b[A\n",
            " 44% 658/1500 [00:14<00:28, 29.08it/s]\u001b[A\n",
            " 44% 663/1500 [00:14<00:25, 32.82it/s]\u001b[A\n",
            " 45% 668/1500 [00:15<00:28, 29.62it/s]\u001b[A\n",
            " 45% 672/1500 [00:15<00:26, 30.73it/s]\u001b[A\n",
            " 45% 676/1500 [00:15<00:26, 31.04it/s]\u001b[A\n",
            " 45% 680/1500 [00:15<00:24, 32.97it/s]\u001b[A\n",
            " 46% 684/1500 [00:15<00:33, 24.22it/s]\u001b[A\n",
            " 46% 687/1500 [00:15<00:32, 24.73it/s]\u001b[A\n",
            " 46% 692/1500 [00:15<00:28, 28.85it/s]\u001b[A\n",
            " 47% 698/1500 [00:16<00:22, 35.16it/s]\u001b[A\n",
            " 47% 702/1500 [00:16<00:32, 24.79it/s]\u001b[A\n",
            " 47% 706/1500 [00:16<00:38, 20.52it/s]\u001b[A\n",
            " 47% 709/1500 [00:16<00:42, 18.63it/s]\u001b[A\n",
            " 48% 714/1500 [00:16<00:33, 23.29it/s]\u001b[A\n",
            " 48% 718/1500 [00:17<00:31, 25.20it/s]\u001b[A\n",
            " 48% 721/1500 [00:17<00:35, 22.05it/s]\u001b[A\n",
            " 48% 726/1500 [00:17<00:29, 26.59it/s]\u001b[A\n",
            " 49% 731/1500 [00:17<00:25, 30.33it/s]\u001b[A\n",
            " 49% 735/1500 [00:17<00:24, 31.40it/s]\u001b[A\n",
            " 49% 740/1500 [00:17<00:28, 27.10it/s]\u001b[A\n",
            " 50% 745/1500 [00:18<00:30, 24.59it/s]\u001b[A\n",
            " 50% 750/1500 [00:18<00:25, 28.88it/s]\u001b[A\n",
            " 50% 754/1500 [00:18<00:25, 29.26it/s]\u001b[A\n",
            " 51% 758/1500 [00:18<00:26, 28.23it/s]\u001b[A\n",
            " 51% 762/1500 [00:18<00:24, 30.16it/s]\u001b[A\n",
            " 51% 766/1500 [00:18<00:24, 30.11it/s]\u001b[A\n",
            " 52% 773/1500 [00:18<00:18, 38.71it/s]\u001b[A\n",
            " 52% 780/1500 [00:18<00:15, 46.05it/s]\u001b[A\n",
            " 53% 788/1500 [00:19<00:13, 54.11it/s]\u001b[A\n",
            " 53% 796/1500 [00:19<00:12, 58.49it/s]\u001b[A\n",
            " 54% 803/1500 [00:19<00:14, 48.90it/s]\u001b[A\n",
            " 54% 810/1500 [00:19<00:13, 52.32it/s]\u001b[A\n",
            " 54% 816/1500 [00:19<00:15, 43.01it/s]\u001b[A\n",
            " 55% 823/1500 [00:19<00:13, 48.71it/s]\u001b[A\n",
            " 55% 830/1500 [00:19<00:12, 53.63it/s]\u001b[A\n",
            " 56% 837/1500 [00:19<00:11, 56.52it/s]\u001b[A\n",
            " 56% 845/1500 [00:20<00:11, 59.32it/s]\u001b[A\n",
            " 57% 852/1500 [00:20<00:10, 60.99it/s]\u001b[A\n",
            " 57% 859/1500 [00:20<00:10, 60.97it/s]\u001b[A\n",
            " 58% 868/1500 [00:20<00:09, 67.16it/s]\u001b[A\n",
            " 58% 875/1500 [00:20<00:09, 65.28it/s]\u001b[A\n",
            " 59% 882/1500 [00:20<00:09, 63.18it/s]\u001b[A\n",
            " 59% 890/1500 [00:20<00:09, 66.45it/s]\u001b[A\n",
            " 60% 897/1500 [00:20<00:11, 52.51it/s]\u001b[A\n",
            " 60% 906/1500 [00:21<00:09, 60.06it/s]\u001b[A\n",
            " 61% 913/1500 [00:21<00:10, 56.30it/s]\u001b[A\n",
            " 61% 921/1500 [00:21<00:09, 61.29it/s]\u001b[A\n",
            " 62% 928/1500 [00:21<00:12, 46.07it/s]\u001b[A\n",
            " 62% 936/1500 [00:21<00:10, 51.87it/s]\u001b[A\n",
            " 63% 944/1500 [00:21<00:09, 58.06it/s]\u001b[A\n",
            " 63% 951/1500 [00:21<00:09, 58.89it/s]\u001b[A\n",
            " 64% 959/1500 [00:22<00:08, 63.80it/s]\u001b[A\n",
            " 65% 968/1500 [00:22<00:07, 70.07it/s]\u001b[A\n",
            " 65% 976/1500 [00:22<00:08, 58.60it/s]\u001b[A\n",
            " 66% 983/1500 [00:22<00:08, 60.71it/s]\u001b[A\n",
            " 66% 990/1500 [00:22<00:08, 60.91it/s]\u001b[A\n",
            " 66% 997/1500 [00:22<00:09, 54.60it/s]\u001b[A\n",
            " 67% 1003/1500 [00:22<00:09, 55.02it/s]\u001b[A\n",
            " 67% 1010/1500 [00:22<00:08, 58.67it/s]\u001b[A\n",
            " 68% 1018/1500 [00:23<00:07, 62.12it/s]\u001b[A\n",
            " 68% 1027/1500 [00:23<00:07, 66.31it/s]\u001b[A\n",
            " 69% 1034/1500 [00:23<00:09, 50.35it/s]\u001b[A\n",
            " 69% 1041/1500 [00:23<00:08, 54.15it/s]\u001b[A\n",
            " 70% 1051/1500 [00:23<00:07, 63.46it/s]\u001b[A\n",
            " 71% 1058/1500 [00:23<00:08, 54.87it/s]\u001b[A\n",
            " 71% 1065/1500 [00:23<00:07, 58.31it/s]\u001b[A\n",
            " 71% 1072/1500 [00:24<00:08, 51.92it/s]\u001b[A\n",
            " 72% 1080/1500 [00:24<00:07, 56.75it/s]\u001b[A\n",
            " 73% 1088/1500 [00:24<00:06, 60.76it/s]\u001b[A\n",
            " 73% 1095/1500 [00:24<00:06, 62.70it/s]\u001b[A\n",
            " 73% 1102/1500 [00:24<00:06, 60.87it/s]\u001b[A\n",
            " 74% 1112/1500 [00:24<00:05, 66.23it/s]\u001b[A\n",
            " 75% 1119/1500 [00:24<00:07, 52.33it/s]\u001b[A\n",
            " 75% 1126/1500 [00:24<00:06, 55.17it/s]\u001b[A\n",
            " 75% 1132/1500 [00:25<00:06, 55.91it/s]\u001b[A\n",
            " 76% 1139/1500 [00:25<00:06, 57.73it/s]\u001b[A\n",
            " 76% 1146/1500 [00:25<00:05, 60.37it/s]\u001b[A\n",
            " 77% 1153/1500 [00:25<00:06, 52.63it/s]\u001b[A\n",
            " 77% 1160/1500 [00:25<00:06, 55.60it/s]\u001b[A\n",
            " 78% 1169/1500 [00:25<00:05, 62.28it/s]\u001b[A\n",
            " 78% 1177/1500 [00:25<00:05, 63.59it/s]\u001b[A\n",
            " 79% 1184/1500 [00:25<00:05, 57.54it/s]\u001b[A\n",
            " 79% 1191/1500 [00:26<00:05, 59.00it/s]\u001b[A\n",
            " 80% 1198/1500 [00:26<00:05, 59.48it/s]\u001b[A\n",
            " 80% 1205/1500 [00:26<00:04, 62.15it/s]\u001b[A\n",
            " 81% 1212/1500 [00:26<00:05, 55.17it/s]\u001b[A\n",
            " 81% 1218/1500 [00:26<00:05, 48.18it/s]\u001b[A\n",
            " 82% 1226/1500 [00:26<00:04, 55.04it/s]\u001b[A\n",
            " 82% 1232/1500 [00:26<00:05, 45.96it/s]\u001b[A\n",
            " 83% 1238/1500 [00:26<00:05, 47.74it/s]\u001b[A\n",
            " 83% 1244/1500 [00:27<00:05, 43.46it/s]\u001b[A\n",
            " 83% 1249/1500 [00:27<00:06, 39.00it/s]\u001b[A\n",
            " 84% 1258/1500 [00:27<00:05, 48.28it/s]\u001b[A\n",
            " 84% 1264/1500 [00:27<00:05, 45.51it/s]\u001b[A\n",
            " 85% 1273/1500 [00:27<00:04, 55.45it/s]\u001b[A\n",
            " 85% 1281/1500 [00:27<00:03, 60.87it/s]\u001b[A\n",
            " 86% 1288/1500 [00:27<00:03, 59.00it/s]\u001b[A\n",
            " 86% 1295/1500 [00:28<00:03, 58.06it/s]\u001b[A\n",
            " 87% 1302/1500 [00:28<00:03, 50.05it/s]\u001b[A\n",
            " 87% 1310/1500 [00:28<00:03, 54.30it/s]\u001b[A\n",
            " 88% 1319/1500 [00:28<00:02, 61.14it/s]\u001b[A\n",
            " 88% 1327/1500 [00:28<00:02, 65.66it/s]\u001b[A\n",
            " 89% 1334/1500 [00:28<00:02, 62.75it/s]\u001b[A\n",
            " 89% 1341/1500 [00:28<00:03, 48.74it/s]\u001b[A\n",
            " 90% 1347/1500 [00:29<00:03, 44.44it/s]\u001b[A\n",
            " 90% 1354/1500 [00:29<00:02, 48.96it/s]\u001b[A\n",
            " 91% 1360/1500 [00:29<00:03, 42.52it/s]\u001b[A\n",
            " 91% 1365/1500 [00:29<00:03, 34.55it/s]\u001b[A\n",
            " 91% 1369/1500 [00:29<00:03, 34.32it/s]\u001b[A\n",
            " 92% 1375/1500 [00:29<00:03, 38.62it/s]\u001b[A\n",
            " 92% 1380/1500 [00:29<00:02, 40.34it/s]\u001b[A\n",
            " 92% 1385/1500 [00:30<00:02, 38.88it/s]\u001b[A\n",
            " 93% 1390/1500 [00:30<00:02, 39.47it/s]\u001b[A\n",
            " 93% 1395/1500 [00:30<00:03, 29.58it/s]\u001b[A\n",
            " 93% 1399/1500 [00:30<00:03, 31.33it/s]\u001b[A\n",
            " 94% 1405/1500 [00:30<00:03, 27.40it/s]\u001b[A\n",
            " 94% 1409/1500 [00:30<00:03, 29.66it/s]\u001b[A\n",
            " 94% 1414/1500 [00:31<00:02, 32.94it/s]\u001b[A\n",
            " 95% 1419/1500 [00:31<00:02, 36.11it/s]\u001b[A\n",
            " 95% 1424/1500 [00:31<00:02, 37.14it/s]\u001b[A\n",
            " 95% 1429/1500 [00:31<00:01, 39.22it/s]\u001b[A\n",
            " 96% 1434/1500 [00:31<00:01, 41.59it/s]\u001b[A\n",
            " 96% 1439/1500 [00:31<00:01, 41.40it/s]\u001b[A\n",
            " 96% 1445/1500 [00:31<00:01, 43.41it/s]\u001b[A\n",
            " 97% 1450/1500 [00:31<00:01, 40.69it/s]\u001b[A\n",
            " 97% 1455/1500 [00:32<00:01, 35.07it/s]\u001b[A\n",
            " 97% 1459/1500 [00:32<00:01, 34.81it/s]\u001b[A\n",
            " 98% 1463/1500 [00:32<00:01, 35.07it/s]\u001b[A\n",
            " 98% 1467/1500 [00:32<00:00, 35.97it/s]\u001b[A\n",
            " 98% 1471/1500 [00:32<00:01, 23.63it/s]\u001b[A\n",
            " 98% 1475/1500 [00:32<00:00, 25.97it/s]\u001b[A\n",
            " 99% 1480/1500 [00:32<00:00, 29.65it/s]\u001b[A\n",
            " 99% 1484/1500 [00:33<00:00, 30.15it/s]\u001b[A\n",
            " 99% 1489/1500 [00:33<00:00, 33.35it/s]\u001b[A\n",
            "100% 1493/1500 [00:33<00:00, 24.84it/s]\u001b[A\n",
            "100% 1500/1500 [00:33<00:00, 44.62it/s]\n",
            "08/13/2023 16:58:06 - INFO - __main__ - Saving predictions to drive/MyDrive/adapter_medical_fusion_squad2/predict_predictions.json.\n",
            "08/13/2023 16:58:06 - INFO - __main__ - Saving nbest_preds to drive/MyDrive/adapter_medical_fusion_squad2/predict_nbest_predictions.json.\n",
            "***** predict metrics *****\n",
            "  predict_samples         =       8500\n",
            "  test_exact_match        =     5.0667\n",
            "  test_f1                 =    33.0893\n",
            "  test_runtime            = 0:05:14.02\n",
            "  test_samples_per_second =     27.068\n",
            "  test_steps_per_second   =      3.385\n",
            "[INFO|modelcard.py:449] 2023-08-13 16:58:08,055 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n",
            "100% 1063/1063 [06:00<00:00,  2.95it/s]\n"
          ]
        }
      ],
      "source": [
        "!python drive/MyDrive/testqa4.py --model_name_or_path 'bert-base-uncased' --output_dir \"drive/MyDrive/adapter_medical_fusion_squad2\" --train_file \"drive/MyDrive/train_medical.json\" --test_file \"drive/MyDrive/val_medical.json\" --do_predict True --do_train True --overwrite_output_dir True --save_total_limit 2"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
